{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WVyV2RoHvH1U"
   },
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## installing necessary libraries and modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K6RXn2p8uNvk",
    "outputId": "6819958b-7cd2-435b-d004-28934b53e8d8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\Users\\91797\\AppData\\Local\\Programs\\Python\\Python312\\Scripts\\pip.exe\\__main__.py\", line 4, in <module>\n",
      "ModuleNotFoundError: No module named 'pip'\n",
      "c:\\Users\\91797\\AppData\\Local\\Programs\\Python\\Python312\\python.exe: No module named pip\n",
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\Users\\91797\\AppData\\Local\\Programs\\Python\\Python312\\Scripts\\pip.exe\\__main__.py\", line 4, in <module>\n",
      "ModuleNotFoundError: No module named 'pip'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "! pip install pandas\n",
    "! python -m pip install \"pymongo[srv]\"\n",
    "! pip install mysql-connector-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## importing the requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X6Pe7oIQvUKH"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pymongo.mongo_client import MongoClient\n",
    "from pymongo.server_api import ServerApi\n",
    "import mysql.connector\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "cjeVxSOXvZX8"
   },
   "outputs": [],
   "source": [
    "# reading the CSV data file\n",
    "\n",
    "df = pd.read_csv(\"C:\\\\Users\\\\91797\\\\OneDrive\\\\Desktop\\\\app\\\\census_2011.csv\", header = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 652
    },
    "id": "Gvbt7sWownqc",
    "outputId": "194bd003-38e5-4c3d-df58-4c28adfd6b91"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>District code</th>\n",
       "      <th>State name</th>\n",
       "      <th>District name</th>\n",
       "      <th>Population</th>\n",
       "      <th>Male</th>\n",
       "      <th>Female</th>\n",
       "      <th>Literate</th>\n",
       "      <th>Male_Literate</th>\n",
       "      <th>Female_Literate</th>\n",
       "      <th>SC</th>\n",
       "      <th>...</th>\n",
       "      <th>Power_Parity_Rs_90000_150000</th>\n",
       "      <th>Power_Parity_Rs_45000_150000</th>\n",
       "      <th>Power_Parity_Rs_150000_240000</th>\n",
       "      <th>Power_Parity_Rs_240000_330000</th>\n",
       "      <th>Power_Parity_Rs_150000_330000</th>\n",
       "      <th>Power_Parity_Rs_330000_425000</th>\n",
       "      <th>Power_Parity_Rs_425000_545000</th>\n",
       "      <th>Power_Parity_Rs_330000_545000</th>\n",
       "      <th>Power_Parity_Above_Rs_545000</th>\n",
       "      <th>Total_Power_Parity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>JAMMU AND KASHMIR</td>\n",
       "      <td>Kupwara</td>\n",
       "      <td>870354.0</td>\n",
       "      <td>474190.0</td>\n",
       "      <td>396164.0</td>\n",
       "      <td>439654.0</td>\n",
       "      <td>282823.0</td>\n",
       "      <td>156831.0</td>\n",
       "      <td>1048.0</td>\n",
       "      <td>...</td>\n",
       "      <td>94.0</td>\n",
       "      <td>588.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1119.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>JAMMU AND KASHMIR</td>\n",
       "      <td>Badgam</td>\n",
       "      <td>753745.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>355704.0</td>\n",
       "      <td>335649.0</td>\n",
       "      <td>207741.0</td>\n",
       "      <td>127908.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>126.0</td>\n",
       "      <td>562.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1066.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>JAMMU AND KASHMIR</td>\n",
       "      <td>Leh(Ladakh)</td>\n",
       "      <td>133487.0</td>\n",
       "      <td>78971.0</td>\n",
       "      <td>54516.0</td>\n",
       "      <td>93770.0</td>\n",
       "      <td>62834.0</td>\n",
       "      <td>30936.0</td>\n",
       "      <td>488.0</td>\n",
       "      <td>...</td>\n",
       "      <td>46.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.0</td>\n",
       "      <td>242.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>JAMMU AND KASHMIR</td>\n",
       "      <td>Kargil</td>\n",
       "      <td>140802.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>63017.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>56301.0</td>\n",
       "      <td>29935.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>...</td>\n",
       "      <td>27.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>214.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>JAMMU AND KASHMIR</td>\n",
       "      <td>Punch</td>\n",
       "      <td>NaN</td>\n",
       "      <td>251899.0</td>\n",
       "      <td>224936.0</td>\n",
       "      <td>261724.0</td>\n",
       "      <td>163333.0</td>\n",
       "      <td>98391.0</td>\n",
       "      <td>556.0</td>\n",
       "      <td>...</td>\n",
       "      <td>78.0</td>\n",
       "      <td>346.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>629.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>636</td>\n",
       "      <td>PONDICHERRY</td>\n",
       "      <td>Mahe</td>\n",
       "      <td>41816.0</td>\n",
       "      <td>19143.0</td>\n",
       "      <td>22673.0</td>\n",
       "      <td>36470.0</td>\n",
       "      <td>16610.0</td>\n",
       "      <td>19860.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2316.0</td>\n",
       "      <td>4309.0</td>\n",
       "      <td>1370.0</td>\n",
       "      <td>838.0</td>\n",
       "      <td>2208.0</td>\n",
       "      <td>576.0</td>\n",
       "      <td>978.0</td>\n",
       "      <td>1554.0</td>\n",
       "      <td>1446.0</td>\n",
       "      <td>10027.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>637</td>\n",
       "      <td>PONDICHERRY</td>\n",
       "      <td>Karaikal</td>\n",
       "      <td>200222.0</td>\n",
       "      <td>97809.0</td>\n",
       "      <td>102413.0</td>\n",
       "      <td>154916.0</td>\n",
       "      <td>79903.0</td>\n",
       "      <td>75013.0</td>\n",
       "      <td>35348.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1063.0</td>\n",
       "      <td>2408.0</td>\n",
       "      <td>665.0</td>\n",
       "      <td>340.0</td>\n",
       "      <td>1005.0</td>\n",
       "      <td>246.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>729.0</td>\n",
       "      <td>341.0</td>\n",
       "      <td>4890.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>638</td>\n",
       "      <td>ANDAMAN AND NICOBAR ISLANDS</td>\n",
       "      <td>Nicobars</td>\n",
       "      <td>36842.0</td>\n",
       "      <td>20727.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25332.0</td>\n",
       "      <td>15397.0</td>\n",
       "      <td>9935.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>685.0</td>\n",
       "      <td>1895.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>346.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>3151.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638</th>\n",
       "      <td>639</td>\n",
       "      <td>ANDAMAN AND NICOBAR ISLANDS</td>\n",
       "      <td>North  AND Middle Andaman</td>\n",
       "      <td>105597.0</td>\n",
       "      <td>54861.0</td>\n",
       "      <td>50736.0</td>\n",
       "      <td>78683.0</td>\n",
       "      <td>43186.0</td>\n",
       "      <td>35497.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>685.0</td>\n",
       "      <td>1895.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>346.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>3151.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>640</td>\n",
       "      <td>ANDAMAN AND NICOBAR ISLANDS</td>\n",
       "      <td>South Andaman</td>\n",
       "      <td>NaN</td>\n",
       "      <td>127283.0</td>\n",
       "      <td>110859.0</td>\n",
       "      <td>190266.0</td>\n",
       "      <td>105794.0</td>\n",
       "      <td>84472.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1371.0</td>\n",
       "      <td>3020.0</td>\n",
       "      <td>649.0</td>\n",
       "      <td>368.0</td>\n",
       "      <td>1017.0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>497.0</td>\n",
       "      <td>762.0</td>\n",
       "      <td>376.0</td>\n",
       "      <td>5782.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>640 rows × 118 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     District code                   State name              District name  \\\n",
       "0                1            JAMMU AND KASHMIR                    Kupwara   \n",
       "1                2            JAMMU AND KASHMIR                     Badgam   \n",
       "2                3            JAMMU AND KASHMIR                Leh(Ladakh)   \n",
       "3                4            JAMMU AND KASHMIR                     Kargil   \n",
       "4                5            JAMMU AND KASHMIR                      Punch   \n",
       "..             ...                          ...                        ...   \n",
       "635            636                  PONDICHERRY                       Mahe   \n",
       "636            637                  PONDICHERRY                   Karaikal   \n",
       "637            638  ANDAMAN AND NICOBAR ISLANDS                   Nicobars   \n",
       "638            639  ANDAMAN AND NICOBAR ISLANDS  North  AND Middle Andaman   \n",
       "639            640  ANDAMAN AND NICOBAR ISLANDS              South Andaman   \n",
       "\n",
       "     Population      Male    Female  Literate  Male_Literate  Female_Literate  \\\n",
       "0      870354.0  474190.0  396164.0  439654.0       282823.0         156831.0   \n",
       "1      753745.0       NaN  355704.0  335649.0       207741.0         127908.0   \n",
       "2      133487.0   78971.0   54516.0   93770.0        62834.0          30936.0   \n",
       "3      140802.0       NaN   63017.0       NaN        56301.0          29935.0   \n",
       "4           NaN  251899.0  224936.0  261724.0       163333.0          98391.0   \n",
       "..          ...       ...       ...       ...            ...              ...   \n",
       "635     41816.0   19143.0   22673.0   36470.0        16610.0          19860.0   \n",
       "636    200222.0   97809.0  102413.0  154916.0        79903.0          75013.0   \n",
       "637     36842.0   20727.0       NaN   25332.0        15397.0           9935.0   \n",
       "638    105597.0   54861.0   50736.0   78683.0        43186.0          35497.0   \n",
       "639         NaN  127283.0  110859.0  190266.0       105794.0          84472.0   \n",
       "\n",
       "          SC  ...  Power_Parity_Rs_90000_150000  Power_Parity_Rs_45000_150000  \\\n",
       "0     1048.0  ...                          94.0                         588.0   \n",
       "1        NaN  ...                         126.0                         562.0   \n",
       "2      488.0  ...                          46.0                         122.0   \n",
       "3       18.0  ...                          27.0                         114.0   \n",
       "4      556.0  ...                          78.0                         346.0   \n",
       "..       ...  ...                           ...                           ...   \n",
       "635    144.0  ...                        2316.0                        4309.0   \n",
       "636  35348.0  ...                        1063.0                        2408.0   \n",
       "637      0.0  ...                         685.0                        1895.0   \n",
       "638      0.0  ...                         685.0                        1895.0   \n",
       "639      0.0  ...                        1371.0                        3020.0   \n",
       "\n",
       "     Power_Parity_Rs_150000_240000  Power_Parity_Rs_240000_330000  \\\n",
       "0                             71.0                          101.0   \n",
       "1                             72.0                           89.0   \n",
       "2                             15.0                           22.0   \n",
       "3                             12.0                           18.0   \n",
       "4                             35.0                           50.0   \n",
       "..                             ...                            ...   \n",
       "635                         1370.0                          838.0   \n",
       "636                          665.0                          340.0   \n",
       "637                          212.0                          134.0   \n",
       "638                          212.0                            NaN   \n",
       "639                          649.0                          368.0   \n",
       "\n",
       "     Power_Parity_Rs_150000_330000  Power_Parity_Rs_330000_425000  \\\n",
       "0                            172.0                           74.0   \n",
       "1                            161.0                           96.0   \n",
       "2                              NaN                           20.0   \n",
       "3                             30.0                           19.0   \n",
       "4                             85.0                           59.0   \n",
       "..                             ...                            ...   \n",
       "635                         2208.0                          576.0   \n",
       "636                         1005.0                          246.0   \n",
       "637                          346.0                           70.0   \n",
       "638                          346.0                           70.0   \n",
       "639                         1017.0                          265.0   \n",
       "\n",
       "     Power_Parity_Rs_425000_545000  Power_Parity_Rs_330000_545000  \\\n",
       "0                             10.0                           84.0   \n",
       "1                             28.0                          124.0   \n",
       "2                              NaN                            NaN   \n",
       "3                              3.0                           22.0   \n",
       "4                              8.0                           67.0   \n",
       "..                             ...                            ...   \n",
       "635                          978.0                         1554.0   \n",
       "636                            NaN                          729.0   \n",
       "637                          120.0                          190.0   \n",
       "638                          120.0                          190.0   \n",
       "639                          497.0                          762.0   \n",
       "\n",
       "     Power_Parity_Above_Rs_545000  Total_Power_Parity  \n",
       "0                            15.0              1119.0  \n",
       "1                            18.0              1066.0  \n",
       "2                            17.0               242.0  \n",
       "3                             7.0               214.0  \n",
       "4                            12.0               629.0  \n",
       "..                            ...                 ...  \n",
       "635                        1446.0             10027.0  \n",
       "636                         341.0              4890.0  \n",
       "637                          84.0              3151.0  \n",
       "638                          84.0              3151.0  \n",
       "639                         376.0              5782.0  \n",
       "\n",
       "[640 rows x 118 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5TS5zJeUyqHq"
   },
   "source": [
    "### Shape of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KZ8tZc05ywAk",
    "outputId": "47bce6ad-3711-480a-e7a7-c47cc3e6d106"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(640, 118)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3mb7Ap2Yy4oq"
   },
   "source": [
    "The dataset contains 640 rows and 118 columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EyHrzrWmzA9C"
   },
   "source": [
    " ### Summary of the dataset :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 367
    },
    "id": "ffiOKjj7ypvS",
    "outputId": "75d49c52-f3c9-45f9-f9fc-8c59094b4e8a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>District code</th>\n",
       "      <th>Population</th>\n",
       "      <th>Male</th>\n",
       "      <th>Female</th>\n",
       "      <th>Literate</th>\n",
       "      <th>Male_Literate</th>\n",
       "      <th>Female_Literate</th>\n",
       "      <th>SC</th>\n",
       "      <th>Male_SC</th>\n",
       "      <th>Female_SC</th>\n",
       "      <th>...</th>\n",
       "      <th>Power_Parity_Rs_90000_150000</th>\n",
       "      <th>Power_Parity_Rs_45000_150000</th>\n",
       "      <th>Power_Parity_Rs_150000_240000</th>\n",
       "      <th>Power_Parity_Rs_240000_330000</th>\n",
       "      <th>Power_Parity_Rs_150000_330000</th>\n",
       "      <th>Power_Parity_Rs_330000_425000</th>\n",
       "      <th>Power_Parity_Rs_425000_545000</th>\n",
       "      <th>Power_Parity_Rs_330000_545000</th>\n",
       "      <th>Power_Parity_Above_Rs_545000</th>\n",
       "      <th>Total_Power_Parity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>640.000000</td>\n",
       "      <td>6.100000e+02</td>\n",
       "      <td>6.100000e+02</td>\n",
       "      <td>6.070000e+02</td>\n",
       "      <td>6.040000e+02</td>\n",
       "      <td>6.090000e+02</td>\n",
       "      <td>6.130000e+02</td>\n",
       "      <td>6.050000e+02</td>\n",
       "      <td>6.170000e+02</td>\n",
       "      <td>6.080000e+02</td>\n",
       "      <td>...</td>\n",
       "      <td>607.000000</td>\n",
       "      <td>610.000000</td>\n",
       "      <td>611.000000</td>\n",
       "      <td>605.000000</td>\n",
       "      <td>616.000000</td>\n",
       "      <td>607.000000</td>\n",
       "      <td>610.000000</td>\n",
       "      <td>617.000000</td>\n",
       "      <td>610.000000</td>\n",
       "      <td>608.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>320.500000</td>\n",
       "      <td>1.852620e+06</td>\n",
       "      <td>9.685726e+05</td>\n",
       "      <td>9.139882e+05</td>\n",
       "      <td>1.190550e+06</td>\n",
       "      <td>6.739088e+05</td>\n",
       "      <td>5.129481e+05</td>\n",
       "      <td>3.177854e+05</td>\n",
       "      <td>1.624509e+05</td>\n",
       "      <td>1.544700e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>792.028007</td>\n",
       "      <td>1676.009836</td>\n",
       "      <td>288.960720</td>\n",
       "      <td>213.919008</td>\n",
       "      <td>513.099026</td>\n",
       "      <td>197.375618</td>\n",
       "      <td>264.191803</td>\n",
       "      <td>463.019449</td>\n",
       "      <td>283.934426</td>\n",
       "      <td>3334.167763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>184.896367</td>\n",
       "      <td>1.435578e+06</td>\n",
       "      <td>7.926455e+05</td>\n",
       "      <td>7.479293e+05</td>\n",
       "      <td>1.050630e+06</td>\n",
       "      <td>5.683384e+05</td>\n",
       "      <td>4.801441e+05</td>\n",
       "      <td>3.172010e+05</td>\n",
       "      <td>1.625607e+05</td>\n",
       "      <td>1.537418e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>1059.010710</td>\n",
       "      <td>1669.641260</td>\n",
       "      <td>641.765892</td>\n",
       "      <td>370.466703</td>\n",
       "      <td>985.702797</td>\n",
       "      <td>433.595214</td>\n",
       "      <td>599.182627</td>\n",
       "      <td>1023.577867</td>\n",
       "      <td>1073.822380</td>\n",
       "      <td>4683.995495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.004000e+03</td>\n",
       "      <td>4.414000e+03</td>\n",
       "      <td>3.590000e+03</td>\n",
       "      <td>4.436000e+03</td>\n",
       "      <td>2.614000e+03</td>\n",
       "      <td>1.822000e+03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>160.750000</td>\n",
       "      <td>8.148625e+05</td>\n",
       "      <td>4.180382e+05</td>\n",
       "      <td>3.986990e+05</td>\n",
       "      <td>4.796545e+05</td>\n",
       "      <td>2.695820e+05</td>\n",
       "      <td>2.009450e+05</td>\n",
       "      <td>8.799100e+04</td>\n",
       "      <td>4.251300e+04</td>\n",
       "      <td>4.411825e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>236.000000</td>\n",
       "      <td>588.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>93.500000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1053.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>320.500000</td>\n",
       "      <td>1.557367e+06</td>\n",
       "      <td>7.939620e+05</td>\n",
       "      <td>7.556020e+05</td>\n",
       "      <td>9.793575e+05</td>\n",
       "      <td>5.507160e+05</td>\n",
       "      <td>4.048610e+05</td>\n",
       "      <td>2.463370e+05</td>\n",
       "      <td>1.252140e+05</td>\n",
       "      <td>1.181440e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>507.000000</td>\n",
       "      <td>1196.000000</td>\n",
       "      <td>144.000000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>274.000000</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>188.000000</td>\n",
       "      <td>61.500000</td>\n",
       "      <td>2291.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>480.250000</td>\n",
       "      <td>2.565248e+06</td>\n",
       "      <td>1.318615e+06</td>\n",
       "      <td>1.253832e+06</td>\n",
       "      <td>1.602260e+06</td>\n",
       "      <td>9.203140e+05</td>\n",
       "      <td>6.568420e+05</td>\n",
       "      <td>4.550620e+05</td>\n",
       "      <td>2.284310e+05</td>\n",
       "      <td>2.163095e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>939.000000</td>\n",
       "      <td>2224.250000</td>\n",
       "      <td>293.000000</td>\n",
       "      <td>253.000000</td>\n",
       "      <td>562.250000</td>\n",
       "      <td>216.000000</td>\n",
       "      <td>293.000000</td>\n",
       "      <td>509.000000</td>\n",
       "      <td>212.750000</td>\n",
       "      <td>3985.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>640.000000</td>\n",
       "      <td>1.000978e+07</td>\n",
       "      <td>5.865078e+06</td>\n",
       "      <td>5.195070e+06</td>\n",
       "      <td>8.227161e+06</td>\n",
       "      <td>4.591396e+06</td>\n",
       "      <td>3.635765e+06</td>\n",
       "      <td>2.464032e+06</td>\n",
       "      <td>1.266504e+06</td>\n",
       "      <td>1.197528e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>10334.000000</td>\n",
       "      <td>13483.000000</td>\n",
       "      <td>10835.000000</td>\n",
       "      <td>3595.000000</td>\n",
       "      <td>14430.000000</td>\n",
       "      <td>5027.000000</td>\n",
       "      <td>7597.000000</td>\n",
       "      <td>12624.000000</td>\n",
       "      <td>18289.000000</td>\n",
       "      <td>60163.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 116 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       District code    Population          Male        Female      Literate  \\\n",
       "count     640.000000  6.100000e+02  6.100000e+02  6.070000e+02  6.040000e+02   \n",
       "mean      320.500000  1.852620e+06  9.685726e+05  9.139882e+05  1.190550e+06   \n",
       "std       184.896367  1.435578e+06  7.926455e+05  7.479293e+05  1.050630e+06   \n",
       "min         1.000000  8.004000e+03  4.414000e+03  3.590000e+03  4.436000e+03   \n",
       "25%       160.750000  8.148625e+05  4.180382e+05  3.986990e+05  4.796545e+05   \n",
       "50%       320.500000  1.557367e+06  7.939620e+05  7.556020e+05  9.793575e+05   \n",
       "75%       480.250000  2.565248e+06  1.318615e+06  1.253832e+06  1.602260e+06   \n",
       "max       640.000000  1.000978e+07  5.865078e+06  5.195070e+06  8.227161e+06   \n",
       "\n",
       "       Male_Literate  Female_Literate            SC       Male_SC  \\\n",
       "count   6.090000e+02     6.130000e+02  6.050000e+02  6.170000e+02   \n",
       "mean    6.739088e+05     5.129481e+05  3.177854e+05  1.624509e+05   \n",
       "std     5.683384e+05     4.801441e+05  3.172010e+05  1.625607e+05   \n",
       "min     2.614000e+03     1.822000e+03  0.000000e+00  0.000000e+00   \n",
       "25%     2.695820e+05     2.009450e+05  8.799100e+04  4.251300e+04   \n",
       "50%     5.507160e+05     4.048610e+05  2.463370e+05  1.252140e+05   \n",
       "75%     9.203140e+05     6.568420e+05  4.550620e+05  2.284310e+05   \n",
       "max     4.591396e+06     3.635765e+06  2.464032e+06  1.266504e+06   \n",
       "\n",
       "          Female_SC  ...  Power_Parity_Rs_90000_150000  \\\n",
       "count  6.080000e+02  ...                    607.000000   \n",
       "mean   1.544700e+05  ...                    792.028007   \n",
       "std    1.537418e+05  ...                   1059.010710   \n",
       "min    0.000000e+00  ...                      0.000000   \n",
       "25%    4.411825e+04  ...                    236.000000   \n",
       "50%    1.181440e+05  ...                    507.000000   \n",
       "75%    2.163095e+05  ...                    939.000000   \n",
       "max    1.197528e+06  ...                  10334.000000   \n",
       "\n",
       "       Power_Parity_Rs_45000_150000  Power_Parity_Rs_150000_240000  \\\n",
       "count                    610.000000                     611.000000   \n",
       "mean                    1676.009836                     288.960720   \n",
       "std                     1669.641260                     641.765892   \n",
       "min                        0.000000                       0.000000   \n",
       "25%                      588.000000                      59.000000   \n",
       "50%                     1196.000000                     144.000000   \n",
       "75%                     2224.250000                     293.000000   \n",
       "max                    13483.000000                   10835.000000   \n",
       "\n",
       "       Power_Parity_Rs_240000_330000  Power_Parity_Rs_150000_330000  \\\n",
       "count                     605.000000                     616.000000   \n",
       "mean                      213.919008                     513.099026   \n",
       "std                       370.466703                     985.702797   \n",
       "min                         0.000000                       0.000000   \n",
       "25%                        23.000000                      93.500000   \n",
       "50%                       107.000000                     274.000000   \n",
       "75%                       253.000000                     562.250000   \n",
       "max                      3595.000000                   14430.000000   \n",
       "\n",
       "       Power_Parity_Rs_330000_425000  Power_Parity_Rs_425000_545000  \\\n",
       "count                     607.000000                     610.000000   \n",
       "mean                      197.375618                     264.191803   \n",
       "std                       433.595214                     599.182627   \n",
       "min                         0.000000                       0.000000   \n",
       "25%                        19.000000                      21.000000   \n",
       "50%                        84.000000                      84.000000   \n",
       "75%                       216.000000                     293.000000   \n",
       "max                      5027.000000                    7597.000000   \n",
       "\n",
       "       Power_Parity_Rs_330000_545000  Power_Parity_Above_Rs_545000  \\\n",
       "count                     617.000000                    610.000000   \n",
       "mean                      463.019449                    283.934426   \n",
       "std                      1023.577867                   1073.822380   \n",
       "min                         0.000000                      0.000000   \n",
       "25%                        44.000000                     18.000000   \n",
       "50%                       188.000000                     61.500000   \n",
       "75%                       509.000000                    212.750000   \n",
       "max                     12624.000000                  18289.000000   \n",
       "\n",
       "       Total_Power_Parity  \n",
       "count          608.000000  \n",
       "mean          3334.167763  \n",
       "std           4683.995495  \n",
       "min             17.000000  \n",
       "25%           1053.500000  \n",
       "50%           2291.500000  \n",
       "75%           3985.250000  \n",
       "max          60163.000000  \n",
       "\n",
       "[8 rows x 116 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displaying summary for a dataframe\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DBxUqs3wzR2X"
   },
   "source": [
    "### Check Datatypes in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ILpgmd88zUXO",
    "outputId": "2daea381-31ad-40de-c757-dbf1dd319281"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 640 entries, 0 to 639\n",
      "Columns: 118 entries, District code to Total_Power_Parity\n",
      "dtypes: float64(115), int64(1), object(2)\n",
      "memory usage: 590.1+ KB\n"
     ]
    }
   ],
   "source": [
    "# Check Null and Dtypes\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Om-aT_fWzbxN"
   },
   "source": [
    "### Check for all columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CLklA8eGzewY",
    "outputId": "801b9f57-f981-4be6-d755-82eadb343466"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['District code', 'State name', 'District name', 'Population', 'Male',\n",
       "       'Female', 'Literate', 'Male_Literate', 'Female_Literate', 'SC',\n",
       "       ...\n",
       "       'Power_Parity_Rs_90000_150000', 'Power_Parity_Rs_45000_150000',\n",
       "       'Power_Parity_Rs_150000_240000', 'Power_Parity_Rs_240000_330000',\n",
       "       'Power_Parity_Rs_150000_330000', 'Power_Parity_Rs_330000_425000',\n",
       "       'Power_Parity_Rs_425000_545000', 'Power_Parity_Rs_330000_545000',\n",
       "       'Power_Parity_Above_Rs_545000', 'Total_Power_Parity'],\n",
       "      dtype='object', length=118)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fFvvXuDjw3x-"
   },
   "source": [
    "### Task -1 : Renaming the column Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "TE7-aSq8w_WE"
   },
   "outputs": [],
   "source": [
    "# Renaming the columns\n",
    "\n",
    "column_headers = [\n",
    "    {'State name':'State/UT'},\n",
    "    {'District name':'District'},\n",
    "    {'Male_Literate':'Literate_Male'},\n",
    "    {'Female_Literate':'Literate_Female'},\n",
    "    {'Rural_Households':'Households_Rural'},\n",
    "    {'Urban_Households':'Households_Urban'},\n",
    "    {'Age_Group_0_29':'Young_and_Adult'},\n",
    "    {'Age_Group_30_49':'Middle_Aged'},\n",
    "    {'Age_Group_50':'Senior_Citizen'},\n",
    "    {'Age not stated':'Age_Not_Stated'}\n",
    "    ]\n",
    "\n",
    "def rename_col(headers,df):\n",
    "    for i in headers:\n",
    "        df.rename(columns = i, inplace = True)\n",
    "\n",
    "rename_col(column_headers, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 446
    },
    "id": "fDGLzaTYxTKp",
    "outputId": "6cd7c5a9-6be2-465a-a688-dd9731d5dc15"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>District code</th>\n",
       "      <th>State/UT</th>\n",
       "      <th>District</th>\n",
       "      <th>Population</th>\n",
       "      <th>Male</th>\n",
       "      <th>Female</th>\n",
       "      <th>Literate</th>\n",
       "      <th>Literate_Male</th>\n",
       "      <th>Literate_Female</th>\n",
       "      <th>SC</th>\n",
       "      <th>...</th>\n",
       "      <th>Power_Parity_Rs_90000_150000</th>\n",
       "      <th>Power_Parity_Rs_45000_150000</th>\n",
       "      <th>Power_Parity_Rs_150000_240000</th>\n",
       "      <th>Power_Parity_Rs_240000_330000</th>\n",
       "      <th>Power_Parity_Rs_150000_330000</th>\n",
       "      <th>Power_Parity_Rs_330000_425000</th>\n",
       "      <th>Power_Parity_Rs_425000_545000</th>\n",
       "      <th>Power_Parity_Rs_330000_545000</th>\n",
       "      <th>Power_Parity_Above_Rs_545000</th>\n",
       "      <th>Total_Power_Parity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>JAMMU AND KASHMIR</td>\n",
       "      <td>Kupwara</td>\n",
       "      <td>870354.0</td>\n",
       "      <td>474190.0</td>\n",
       "      <td>396164.0</td>\n",
       "      <td>439654.0</td>\n",
       "      <td>282823.0</td>\n",
       "      <td>156831.0</td>\n",
       "      <td>1048.0</td>\n",
       "      <td>...</td>\n",
       "      <td>94.0</td>\n",
       "      <td>588.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1119.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>JAMMU AND KASHMIR</td>\n",
       "      <td>Badgam</td>\n",
       "      <td>753745.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>355704.0</td>\n",
       "      <td>335649.0</td>\n",
       "      <td>207741.0</td>\n",
       "      <td>127908.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>126.0</td>\n",
       "      <td>562.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1066.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>JAMMU AND KASHMIR</td>\n",
       "      <td>Leh(Ladakh)</td>\n",
       "      <td>133487.0</td>\n",
       "      <td>78971.0</td>\n",
       "      <td>54516.0</td>\n",
       "      <td>93770.0</td>\n",
       "      <td>62834.0</td>\n",
       "      <td>30936.0</td>\n",
       "      <td>488.0</td>\n",
       "      <td>...</td>\n",
       "      <td>46.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.0</td>\n",
       "      <td>242.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>JAMMU AND KASHMIR</td>\n",
       "      <td>Kargil</td>\n",
       "      <td>140802.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>63017.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>56301.0</td>\n",
       "      <td>29935.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>...</td>\n",
       "      <td>27.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>214.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>JAMMU AND KASHMIR</td>\n",
       "      <td>Punch</td>\n",
       "      <td>NaN</td>\n",
       "      <td>251899.0</td>\n",
       "      <td>224936.0</td>\n",
       "      <td>261724.0</td>\n",
       "      <td>163333.0</td>\n",
       "      <td>98391.0</td>\n",
       "      <td>556.0</td>\n",
       "      <td>...</td>\n",
       "      <td>78.0</td>\n",
       "      <td>346.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>629.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 118 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   District code           State/UT     District  Population      Male  \\\n",
       "0              1  JAMMU AND KASHMIR      Kupwara    870354.0  474190.0   \n",
       "1              2  JAMMU AND KASHMIR       Badgam    753745.0       NaN   \n",
       "2              3  JAMMU AND KASHMIR  Leh(Ladakh)    133487.0   78971.0   \n",
       "3              4  JAMMU AND KASHMIR       Kargil    140802.0       NaN   \n",
       "4              5  JAMMU AND KASHMIR        Punch         NaN  251899.0   \n",
       "\n",
       "     Female  Literate  Literate_Male  Literate_Female      SC  ...  \\\n",
       "0  396164.0  439654.0       282823.0         156831.0  1048.0  ...   \n",
       "1  355704.0  335649.0       207741.0         127908.0     NaN  ...   \n",
       "2   54516.0   93770.0        62834.0          30936.0   488.0  ...   \n",
       "3   63017.0       NaN        56301.0          29935.0    18.0  ...   \n",
       "4  224936.0  261724.0       163333.0          98391.0   556.0  ...   \n",
       "\n",
       "   Power_Parity_Rs_90000_150000  Power_Parity_Rs_45000_150000  \\\n",
       "0                          94.0                         588.0   \n",
       "1                         126.0                         562.0   \n",
       "2                          46.0                         122.0   \n",
       "3                          27.0                         114.0   \n",
       "4                          78.0                         346.0   \n",
       "\n",
       "   Power_Parity_Rs_150000_240000  Power_Parity_Rs_240000_330000  \\\n",
       "0                           71.0                          101.0   \n",
       "1                           72.0                           89.0   \n",
       "2                           15.0                           22.0   \n",
       "3                           12.0                           18.0   \n",
       "4                           35.0                           50.0   \n",
       "\n",
       "   Power_Parity_Rs_150000_330000  Power_Parity_Rs_330000_425000  \\\n",
       "0                          172.0                           74.0   \n",
       "1                          161.0                           96.0   \n",
       "2                            NaN                           20.0   \n",
       "3                           30.0                           19.0   \n",
       "4                           85.0                           59.0   \n",
       "\n",
       "   Power_Parity_Rs_425000_545000  Power_Parity_Rs_330000_545000  \\\n",
       "0                           10.0                           84.0   \n",
       "1                           28.0                          124.0   \n",
       "2                            NaN                            NaN   \n",
       "3                            3.0                           22.0   \n",
       "4                            8.0                           67.0   \n",
       "\n",
       "   Power_Parity_Above_Rs_545000  Total_Power_Parity  \n",
       "0                          15.0              1119.0  \n",
       "1                          18.0              1066.0  \n",
       "2                          17.0               242.0  \n",
       "3                           7.0               214.0  \n",
       "4                          12.0               629.0  \n",
       "\n",
       "[5 rows x 118 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bH_-dhhZxymd"
   },
   "source": [
    "### Task-2 : Rename State/UT Names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xHnn3ndq0Zfb"
   },
   "source": [
    "- The State/UT names are in all caps in the census data, For uniformity across datasets we use the names so that only the first character of each word in the name is in upper case and the rest are in lower case.\n",
    "\n",
    "- However, if the word is “and” then it should be all lowercase.if you found & symbol replace it with ‘and’\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "XFtqekafx9bt"
   },
   "outputs": [],
   "source": [
    "# We have two for loops. one is outer loop & another is Inner loop\n",
    "# Where Outer for loop to get the state names and  Inner for loop to check if the word is \"and\" else capitalize the word\n",
    "\n",
    "def rename_state_ut(df):\n",
    "    for i in range(len(df)):\n",
    "        x = df.loc[i,'State/UT'].lower().split()\n",
    "        for j in range(len(x)):\n",
    "            if x[j] != 'and':\n",
    "                x[j] = x[j].capitalize()\n",
    "        df.loc[i,'State/UT'] = \" \".join(x)\n",
    "\n",
    "rename_state_ut(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wa2DJmHb1UF2"
   },
   "source": [
    "### Define numerical & Categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jSrQWhrX1ToP",
    "outputId": "2f0bec89-313d-4c3e-b802-80e6ef7ed5af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 116 numerical features : ['District code', 'Population', 'Male', 'Female', 'Literate', 'Literate_Male', 'Literate_Female', 'SC', 'Male_SC', 'Female_SC', 'ST', 'Male_ST', 'Female_ST', 'Workers', 'Male_Workers', 'Female_Workers', 'Main_Workers', 'Marginal_Workers', 'Non_Workers', 'Cultivator_Workers', 'Agricultural_Workers', 'Household_Workers', 'Other_Workers', 'Hindus', 'Muslims', 'Christians', 'Sikhs', 'Buddhists', 'Jains', 'Others_Religions', 'Religion_Not_Stated', 'LPG_or_PNG_Households', 'Housholds_with_Electric_Lighting', 'Households_with_Internet', 'Households_with_Computer', 'Households_Rural', 'Households_Urban', 'Households', 'Below_Primary_Education', 'Primary_Education', 'Middle_Education', 'Secondary_Education', 'Higher_Education', 'Graduate_Education', 'Other_Education', 'Literate_Education', 'Illiterate_Education', 'Total_Education', 'Young_and_Adult', 'Middle_Aged', 'Senior_Citizen', 'Age_Not_Stated', 'Households_with_Bicycle', 'Households_with_Car_Jeep_Van', 'Households_with_Radio_Transistor', 'Households_with_Scooter_Motorcycle_Moped', 'Households_with_Telephone_Mobile_Phone_Landline_only', 'Households_with_Telephone_Mobile_Phone_Mobile_only', 'Households_with_TV_Computer_Laptop_Telephone_mobile_phone_and_Scooter_Car', 'Households_with_Television', 'Households_with_Telephone_Mobile_Phone', 'Households_with_Telephone_Mobile_Phone_Both', 'Condition_of_occupied_census_houses_Dilapidated_Households', 'Households_with_separate_kitchen_Cooking_inside_house', 'Having_bathing_facility_Total_Households', 'Having_latrine_facility_within_the_premises_Total_Households', 'Ownership_Owned_Households', 'Ownership_Rented_Households', 'Type_of_bathing_facility_Enclosure_without_roof_Households', 'Type_of_fuel_used_for_cooking_Any_other_Households', 'Type_of_latrine_facility_Pit_latrine_Households', 'Type_of_latrine_facility_Other_latrine_Households', 'Type_of_latrine_facility_Night_soil_disposed_into_open_drain_Households', 'Type_of_latrine_facility_Flush_pour_flush_latrine_connected_to_other_system_Households', 'Not_having_bathing_facility_within_the_premises_Total_Households', 'Not_having_latrine_facility_within_the_premises_Alternative_source_Open_Households', 'Main_source_of_drinking_water_Un_covered_well_Households', 'Main_source_of_drinking_water_Handpump_Tubewell_Borewell_Households', 'Main_source_of_drinking_water_Spring_Households', 'Main_source_of_drinking_water_River_Canal_Households', 'Main_source_of_drinking_water_Other_sources_Households', 'Main_source_of_drinking_water_Other_sources_Spring_River_Canal_Tank_Pond_Lake_Other_sources__Households', 'Location_of_drinking_water_source_Near_the_premises_Households', 'Location_of_drinking_water_source_Within_the_premises_Households', 'Main_source_of_drinking_water_Tank_Pond_Lake_Households', 'Main_source_of_drinking_water_Tapwater_Households', 'Main_source_of_drinking_water_Tubewell_Borehole_Households', 'Household_size_1_person_Households', 'Household_size_2_persons_Households', 'Household_size_1_to_2_persons', 'Household_size_3_persons_Households', 'Household_size_3_to_5_persons_Households', 'Household_size_4_persons_Households', 'Household_size_5_persons_Households', 'Household_size_6_8_persons_Households', 'Household_size_9_persons_and_above_Households', 'Location_of_drinking_water_source_Away_Households', 'Married_couples_1_Households', 'Married_couples_2_Households', 'Married_couples_3_Households', 'Married_couples_3_or_more_Households', 'Married_couples_4_Households', 'Married_couples_5__Households', 'Married_couples_None_Households', 'Power_Parity_Less_than_Rs_45000', 'Power_Parity_Rs_45000_90000', 'Power_Parity_Rs_90000_150000', 'Power_Parity_Rs_45000_150000', 'Power_Parity_Rs_150000_240000', 'Power_Parity_Rs_240000_330000', 'Power_Parity_Rs_150000_330000', 'Power_Parity_Rs_330000_425000', 'Power_Parity_Rs_425000_545000', 'Power_Parity_Rs_330000_545000', 'Power_Parity_Above_Rs_545000', 'Total_Power_Parity']\n",
      "We have 2 categorical features : ['State/UT', 'District']\n"
     ]
    }
   ],
   "source": [
    "numeric_features =[feature for feature in df.columns if df[feature].dtype != 'O']\n",
    "categorical_features = [feature for feature in df.columns if df[feature].dtype == 'O']\n",
    "\n",
    "#Print columns\n",
    "print('We have {} numerical features : {}'.format(len(numeric_features),numeric_features))\n",
    "print('We have {} categorical features : {}'.format(len(categorical_features),categorical_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 861
    },
    "id": "0xKvviiW1kiX",
    "outputId": "4f718166-e755-442b-e355-b6a8a433b543"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>District code</th>\n",
       "      <th>Population</th>\n",
       "      <th>Male</th>\n",
       "      <th>Female</th>\n",
       "      <th>Literate</th>\n",
       "      <th>Literate_Male</th>\n",
       "      <th>Literate_Female</th>\n",
       "      <th>SC</th>\n",
       "      <th>Male_SC</th>\n",
       "      <th>Female_SC</th>\n",
       "      <th>...</th>\n",
       "      <th>Power_Parity_Rs_90000_150000</th>\n",
       "      <th>Power_Parity_Rs_45000_150000</th>\n",
       "      <th>Power_Parity_Rs_150000_240000</th>\n",
       "      <th>Power_Parity_Rs_240000_330000</th>\n",
       "      <th>Power_Parity_Rs_150000_330000</th>\n",
       "      <th>Power_Parity_Rs_330000_425000</th>\n",
       "      <th>Power_Parity_Rs_425000_545000</th>\n",
       "      <th>Power_Parity_Rs_330000_545000</th>\n",
       "      <th>Power_Parity_Above_Rs_545000</th>\n",
       "      <th>Total_Power_Parity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>870354.0</td>\n",
       "      <td>474190.0</td>\n",
       "      <td>396164.0</td>\n",
       "      <td>439654.0</td>\n",
       "      <td>282823.0</td>\n",
       "      <td>156831.0</td>\n",
       "      <td>1048.0</td>\n",
       "      <td>1046.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>94.0</td>\n",
       "      <td>588.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1119.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>753745.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>355704.0</td>\n",
       "      <td>335649.0</td>\n",
       "      <td>207741.0</td>\n",
       "      <td>127908.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>343.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>...</td>\n",
       "      <td>126.0</td>\n",
       "      <td>562.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1066.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>133487.0</td>\n",
       "      <td>78971.0</td>\n",
       "      <td>54516.0</td>\n",
       "      <td>93770.0</td>\n",
       "      <td>62834.0</td>\n",
       "      <td>30936.0</td>\n",
       "      <td>488.0</td>\n",
       "      <td>444.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>...</td>\n",
       "      <td>46.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.0</td>\n",
       "      <td>242.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>140802.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>63017.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>56301.0</td>\n",
       "      <td>29935.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>27.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>214.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>251899.0</td>\n",
       "      <td>224936.0</td>\n",
       "      <td>261724.0</td>\n",
       "      <td>163333.0</td>\n",
       "      <td>98391.0</td>\n",
       "      <td>556.0</td>\n",
       "      <td>406.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>78.0</td>\n",
       "      <td>346.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>629.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 116 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   District code  Population      Male    Female  Literate  Literate_Male  \\\n",
       "0              1    870354.0  474190.0  396164.0  439654.0       282823.0   \n",
       "1              2    753745.0       NaN  355704.0  335649.0       207741.0   \n",
       "2              3    133487.0   78971.0   54516.0   93770.0        62834.0   \n",
       "3              4    140802.0       NaN   63017.0       NaN        56301.0   \n",
       "4              5         NaN  251899.0  224936.0  261724.0       163333.0   \n",
       "\n",
       "   Literate_Female      SC  Male_SC  Female_SC  ...  \\\n",
       "0         156831.0  1048.0   1046.0        2.0  ...   \n",
       "1         127908.0     NaN    343.0       25.0  ...   \n",
       "2          30936.0   488.0    444.0       44.0  ...   \n",
       "3          29935.0    18.0     12.0        6.0  ...   \n",
       "4          98391.0   556.0    406.0        NaN  ...   \n",
       "\n",
       "   Power_Parity_Rs_90000_150000  Power_Parity_Rs_45000_150000  \\\n",
       "0                          94.0                         588.0   \n",
       "1                         126.0                         562.0   \n",
       "2                          46.0                         122.0   \n",
       "3                          27.0                         114.0   \n",
       "4                          78.0                         346.0   \n",
       "\n",
       "   Power_Parity_Rs_150000_240000  Power_Parity_Rs_240000_330000  \\\n",
       "0                           71.0                          101.0   \n",
       "1                           72.0                           89.0   \n",
       "2                           15.0                           22.0   \n",
       "3                           12.0                           18.0   \n",
       "4                           35.0                           50.0   \n",
       "\n",
       "   Power_Parity_Rs_150000_330000  Power_Parity_Rs_330000_425000  \\\n",
       "0                          172.0                           74.0   \n",
       "1                          161.0                           96.0   \n",
       "2                            NaN                           20.0   \n",
       "3                           30.0                           19.0   \n",
       "4                           85.0                           59.0   \n",
       "\n",
       "   Power_Parity_Rs_425000_545000  Power_Parity_Rs_330000_545000  \\\n",
       "0                           10.0                           84.0   \n",
       "1                           28.0                          124.0   \n",
       "2                            NaN                            NaN   \n",
       "3                            3.0                           22.0   \n",
       "4                            8.0                           67.0   \n",
       "\n",
       "   Power_Parity_Above_Rs_545000  Total_Power_Parity  \n",
       "0                          15.0              1119.0  \n",
       "1                          18.0              1066.0  \n",
       "2                          17.0               242.0  \n",
       "3                           7.0               214.0  \n",
       "4                          12.0               629.0  \n",
       "\n",
       "[5 rows x 116 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[numeric_features].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 373
    },
    "id": "7vAbRQFv2FGi",
    "outputId": "023d6a48-a4ae-44cd-92d5-1e22d18acee9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State/UT</th>\n",
       "      <th>District</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jammu and Kashmir</td>\n",
       "      <td>Kupwara</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jammu and Kashmir</td>\n",
       "      <td>Badgam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jammu and Kashmir</td>\n",
       "      <td>Leh(Ladakh)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jammu and Kashmir</td>\n",
       "      <td>Kargil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jammu and Kashmir</td>\n",
       "      <td>Punch</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            State/UT     District\n",
       "0  Jammu and Kashmir      Kupwara\n",
       "1  Jammu and Kashmir       Badgam\n",
       "2  Jammu and Kashmir  Leh(Ladakh)\n",
       "3  Jammu and Kashmir       Kargil\n",
       "4  Jammu and Kashmir        Punch"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[categorical_features].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YEHbPUPT2axw"
   },
   "source": [
    "### Task -3 New State/UT formation with encoding handling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PvgHzvTS2ghC"
   },
   "source": [
    "- In 2014 Telangana was formed after it split from Andhra Pradesh, The districts that were included in Telangana are stored in Data/Telangana.txt . Read the text file and Rename the State/UT From “Andhra Pradesh” to “Telangana” for the given districts.\n",
    "\n",
    "- In 2019 Ladakh was formed after it split from Jammu and Kashmir, which included the districts Leh and Kargil. Rename the State/UT From “Jammu and Kashmir” to “Ladakh” for the given districts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "2zPlWfWD2WmI"
   },
   "outputs": [],
   "source": [
    "# Reading the txt file\n",
    "\n",
    "with open('C:\\\\Users\\\\91797\\\\OneDrive\\\\Desktop\\\\app\\\\Telangana.txt', 'r') as telangana:\n",
    "    telangana_districts = telangana.read()\n",
    "telangana_districts = telangana_districts.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting the values as Telangana if the districts are in the telangana districts list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TqrFintQ3N3E"
   },
   "outputs": [],
   "source": [
    "def telangana(df):\n",
    "    for i in range(len(df)):\n",
    "        if df.loc[i,'District'] in telangana_districts:\n",
    "            df.loc[i,'State/UT'] = \"Telangana\"\n",
    "\n",
    "telangana(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting the values as Ladakh if the districts are in the ladakh list ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p1UnFVMN3iH_"
   },
   "outputs": [],
   "source": [
    "def ladakh(df):\n",
    "    ladakh = ['Leh', 'Kargil']\n",
    "    for district in ladakh:\n",
    "        for i in range(len(df)):\n",
    "            if district in df.loc[i,'District']:\n",
    "                df.loc[i,'State/UT'] = \"Ladakh\"\n",
    "\n",
    "ladakh(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OVK8kIaZ407d"
   },
   "source": [
    "### Task 4: Find and process Missing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding and storing the Percentage of missing data before cleaning for each column in a separate dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ipyyDZIj3rLc"
   },
   "outputs": [],
   "source": [
    "def missingDataPercent(df) :\n",
    "    missing_data = {}\n",
    "    columns = df.columns\n",
    "    for i in columns:\n",
    "        count = 0\n",
    "        count += len(list(filter(lambda x : x == True, list(df[i].isnull()))))\n",
    "        missing_data[i] = round((count * 100)/len(df), 2)\n",
    "\n",
    "    return missing_data\n",
    "\n",
    "missing_data_before_cleaning = missingDataPercent(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to return if the cell contains null value or not :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TK81QWFE3q-s"
   },
   "outputs": [],
   "source": [
    "def null_values_filter(df,i,column):\n",
    "    return list(df.loc[[i],column].isnull())[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filling up the Population column :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1gT_EQxa5gWO"
   },
   "outputs": [],
   "source": [
    "def fill_population(df):\n",
    "    for i in range(len(df)):\n",
    "        if null_values_filter(df,i,'Population') == True:\n",
    "            if null_values_filter(df,i,'Male') == null_values_filter(df,i,'Female') == False:\n",
    "                df.loc[i,\"Population\"] = int(df.loc[i,\"Male\"] + df.loc[i, \"Female\"])\n",
    "            elif null_values_filter(df,i,'Young_and_Adult') == null_values_filter(df,i,'Middle_Aged') == null_values_filter(df,i,\"Senior_Citizen\") == null_values_filter(df,i,'Age_Not_Stated') == False:\n",
    "                df.loc[i,'Population'] = int(df.loc[i,\"Young_and_Adult\"] + df.loc[i,\"Middle_Aged\"] + df.loc[i, \"Senior_Citizen\"] + df.loc[i,\"Age_Not_Stated\"])\n",
    "            elif null_values_filter(df,i,'Hindus') == null_values_filter(df,i,'Muslims') == null_values_filter(df,i,'Christians') == null_values_filter(df,i,'Sikhs') == null_values_filter(df,i,'Buddhists') == null_values_filter(df,i,'Jains') == null_values_filter(df,i,'Others_Religions') == null_values_filter(df,i,'Religion_Not_Stated') == False:\n",
    "                df.loc[i,'Population'] = int(df.loc[i,'Hindus'] + df.loc[i,'Muslims'] + df.loc[i,'Christians'] + df.loc[i,'Sikhs'] + df.loc[i,'Buddhists'] + df.loc[i,'Jains'] + df.loc[i,'Others_Religions'] + df.loc[i,'Religion_Not_Stated'])\n",
    "            elif null_values_filter(df,i,'Workers') == null_values_filter(df,i,'Non_Workers') == False:\n",
    "                df.loc[i,\"Population\"] = int(df.loc[i,'Workers'] + df.loc[i,'Non_Workers'])\n",
    "\n",
    "fill_population(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filling up the Male population :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ycSwdrc_5mf-"
   },
   "outputs": [],
   "source": [
    "def fill_male(df):\n",
    "    for i in range(len(df)):\n",
    "        if null_values_filter(df,i,'Male') == True:\n",
    "            if null_values_filter(df,i,'Population') == null_values_filter(df,i,'Female') == False:\n",
    "                df.loc[i,\"Male\"] = int(df.loc[i,\"Population\"] - df.loc[i,\"Female\"])\n",
    "\n",
    "fill_male(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filling up the Female population :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RgrvnCr05qik"
   },
   "outputs": [],
   "source": [
    "def fill_female(df):\n",
    "    for i in range(len(df)):\n",
    "        if null_values_filter(df,i,'Female') == True:\n",
    "            if null_values_filter(df,i,'Population') == null_values_filter(df,i,'Male') == False:\n",
    "                df.loc[i,\"Female\"] = int(df.loc[i,\"Population\"] - df.loc[i,\"Male\"])\n",
    "\n",
    "fill_female(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filling up the Literate population :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WAZeYo0O5u8X"
   },
   "outputs": [],
   "source": [
    "def fill_literate(df):\n",
    "    for i in range(len(df)):\n",
    "        if null_values_filter(df,i,'Literate') == True:\n",
    "            if null_values_filter(df,i,'Literate_Male') == null_values_filter(df,i,'Literate_Female') == False:\n",
    "                df.loc[i,\"Literate\"] = int(df.loc[i,\"Literate_Male\"] + df.loc[i,\"Literate_Female\"])\n",
    "\n",
    "fill_literate(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filling up the Literate Male population :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5P35p6fs5zCa"
   },
   "outputs": [],
   "source": [
    "def fill_literate_male(df):\n",
    "    for i in range(len(df)):\n",
    "        if null_values_filter(df,i,'Literate_Male') == True:\n",
    "            if null_values_filter(df,i,'Literate') == null_values_filter(df,i,'Literate_Female') == False:\n",
    "                df.loc[i,\"Literate_Male\"] = int(df.loc[i,\"Literate\"] - df.loc[i,\"Literate_Female\"])\n",
    "\n",
    "fill_literate_male(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filling up the Literate Female population :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2oU_6n4y54H5"
   },
   "outputs": [],
   "source": [
    "def fill_literate_female(df):\n",
    "    for i in range(len(df)):\n",
    "        if null_values_filter(df,i,'Literate_Female') == True:\n",
    "            if null_values_filter(df,i,'Literate') == null_values_filter(df,i,'Literate_Male') == False:\n",
    "                df.loc[i,\"Literate_Female\"] = int(df.loc[i,\"Literate\"] - df.loc[i,\"Literate_Male\"])\n",
    "\n",
    "fill_literate_female(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filling up the SC column :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xW_sYvrd6P5f"
   },
   "outputs": [],
   "source": [
    "def fill_sc(df):\n",
    "    for i in range(len(df)):\n",
    "        if null_values_filter(df,i,'SC') == True:\n",
    "            if null_values_filter(df,i,'Male_SC') == null_values_filter(df,i,'Female_SC') == False:\n",
    "                df.loc[i,\"SC\"] = int(df.loc[i,\"Male_SC\"] + df.loc[i,\"Female_SC\"])\n",
    "\n",
    "fill_sc(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filing up the Male_SC Column :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EmFOOMCz6P2G"
   },
   "outputs": [],
   "source": [
    "def fill_male_sc(df):\n",
    "    for i in range(len(df)):\n",
    "        if null_values_filter(df,i,'Male_SC') == True:\n",
    "            if null_values_filter(df,i,'SC') == null_values_filter(df,i,'Female_SC') == False:\n",
    "                df.loc[i,\"Male_SC\"] = int(df.loc[i,\"SC\"] - df.loc[i,\"Female_SC\"])\n",
    "\n",
    "fill_male_sc(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filing up the Female_SC Column :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qae88TiX6YZW"
   },
   "outputs": [],
   "source": [
    "def fill_female_sc(df):\n",
    "    for i in range(len(df)):\n",
    "        if null_values_filter(df,i,'Female_SC') == True:\n",
    "            if null_values_filter(df,i,'SC') == null_values_filter(df,i,'Male_SC') == False:\n",
    "                df.loc[i,'Female_SC'] = int(df.loc[i,'SC'] - df.loc[i,'Male_SC'])\n",
    "\n",
    "fill_female_sc(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filling up the ST column :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rwl9wm9i6YME"
   },
   "outputs": [],
   "source": [
    "def fill_st(df):\n",
    "    for i in range(len(df)):\n",
    "        if null_values_filter(df,i,'ST') == True:\n",
    "            if null_values_filter(df,i,'Male_ST') == null_values_filter(df,i,'Female_ST') == False:\n",
    "                df.loc[i,\"ST\"] = int(df.loc[i,\"Male_ST\"] + df.loc[i,\"Female_ST\"])\n",
    "\n",
    "fill_st(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filing up the Male_ST Column :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iVkBzGEC532Z"
   },
   "outputs": [],
   "source": [
    "def fill_male_st(df):\n",
    "    for i in range(len(df)):\n",
    "        if null_values_filter(df,i,'Male_ST') == True:\n",
    "            if null_values_filter(df,i,'ST') == null_values_filter(df,i,'Female_ST') == False:\n",
    "                df.loc[i,\"Male_ST\"] = int(df.loc[i,\"ST\"] - df.loc[i,\"Female_ST\"])\n",
    "\n",
    "fill_male_st(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filing up the Female_ST Column :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6W5p30c45y-2"
   },
   "outputs": [],
   "source": [
    "def fill_female_st(df):\n",
    "    for i in range(len(df)):\n",
    "        if null_values_filter(df,i,'Female_ST') == True:\n",
    "            if null_values_filter(df,i,'ST') == null_values_filter(df,i,'Male_ST') == False:\n",
    "                df.loc[i,'Female_ST'] = int(df.loc[i,'ST'] - df.loc[i,'Male_ST'])\n",
    "\n",
    "fill_female_st(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filling up the Workers column :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "83--fgUW6pdc"
   },
   "outputs": [],
   "source": [
    "def fill_workers(df):\n",
    "    for i in range(len(df)):\n",
    "        if null_values_filter(df,i,'Workers') == True:\n",
    "            if null_values_filter(df,i,'Male_Workers') == null_values_filter(df,i,'Female_Workers') == False:\n",
    "                df.loc[i,\"Workers\"] = int(df.loc[i,\"Male_Workers\"] + df.loc[i,\"Female_Workers\"])\n",
    "            elif null_values_filter(df,i,'Main_Workers') == null_values_filter(df,i,'Marginal_Workers') == False:\n",
    "                df.loc[i,\"Workers\"] = int(df.loc[i,\"Main_Workers\"] + df.loc[i,\"Marginal_Workers\"])\n",
    "            elif null_values_filter(df,i,'Population') == null_values_filter(df,i,'Non_Workers') == False:\n",
    "                df.loc[i,\"Workers\"] = int(df.loc[i,\"Population\"] - df.loc[i,\"Non_Workers\"])\n",
    "\n",
    "fill_workers(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filing up the Male_Workers Column :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QwZi7-JR6pLL"
   },
   "outputs": [],
   "source": [
    "def fill_male_workers(df):\n",
    "    for i in range(len(df)):\n",
    "        if null_values_filter(df,i,'Male_Workers') == True:\n",
    "            if null_values_filter(df,i,'Workers') == null_values_filter(df,i,'Female_Workers') == False:\n",
    "                df.loc[i,\"Male_Workers\"] = int(df.loc[i,\"Workers\"] - df.loc[i,\"Female_Workers\"])\n",
    "\n",
    "fill_male_workers(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filing up the Female_Workers Column :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gq8o-6nF6pHO"
   },
   "outputs": [],
   "source": [
    "def fill_female_workers(df):\n",
    "    for i in range(len(df)):\n",
    "        if null_values_filter(df,i,'Female_Workers') == True:\n",
    "            if null_values_filter(df,i,'Workers') == null_values_filter(df,i,'Male_Workers') == False:\n",
    "                df.loc[i,'Female_Workers'] = int(df.loc[i,'Workers'] - df.loc[i,'Male_Workers'])\n",
    "\n",
    "fill_female_workers(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filling up the Main_Workers column :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KvW4QbUe6_20"
   },
   "outputs": [],
   "source": [
    "def fill_main_workers(df):\n",
    "    for i in range(len(df)):\n",
    "        if null_values_filter(df,i,'Main_Workers') == True:\n",
    "            if null_values_filter(df,i,'Workers') == null_values_filter(df,i,'Marginal_Workers') == False:\n",
    "                df.loc[i,'Main_Workers'] = int(df.loc[i,'Workers'] - df.loc[i,'Marginal_Workers'])\n",
    "            if null_values_filter(df,i,'Population') == null_values_filter(df,i,'Non_Workers') == null_values_filter(df,i,'Marginal_Workers') == False:\n",
    "                df.loc[i,\"Main_Workers\"] = int(df.loc[i,'Population'] - (df.loc[i,'Non_Workers'] + df.loc[i,'Marginal_Workers']))\n",
    "\n",
    "fill_main_workers(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filling up the Marginal_Workers column :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lxm3LHPb6_iT"
   },
   "outputs": [],
   "source": [
    "def fill_marginal_workers(df):\n",
    "    for i in range(len(df)):\n",
    "        if null_values_filter(df,i,'Marginal_Workers') == True:\n",
    "            if null_values_filter(df,i,'Workers') == null_values_filter(df,i,'Main_Workers') == False:\n",
    "                df.loc[i,'Marginal_Workers'] = int(df.loc[i,'Workers'] - df.loc[i,'Main_Workers'])\n",
    "            elif null_values_filter(df,i,'Population') == null_values_filter(df,i,'Non_Workers') == null_values_filter(df,i,'Main_Workers') == False:\n",
    "                df.loc[i,'Marginal_Workers'] = int(df.loc[i,'Population'] - (df.loc[i,'Non_Workers'] + df.loc[i,'Main_Workers']))\n",
    "\n",
    "fill_marginal_workers(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filling up the Non_Workers column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9denEm456_em"
   },
   "outputs": [],
   "source": [
    "def fill_non_workers(df):\n",
    "    for i in range(len(df)):\n",
    "        if null_values_filter(df,i,'Non_Workers') == True:\n",
    "            if null_values_filter(df,i,'Population') == null_values_filter(df,i,'Workers') == False:\n",
    "                df.loc[i,'Non_Workers'] = int(df.loc[i,'Population'] - df.loc[i,'Workers'])\n",
    "            elif null_values_filter(df,i,'Population') == null_values_filter(df,i,'Main_Workers') == null_values_filter(df,i,'Marginal_Workers') == False:\n",
    "                df.loc[i,'Non_Workers'] = int(df.loc[i,'Population'] - (df.loc[i,\"Main_Workers\"] + df.loc[i,\"Marginal_Workers\"]))\n",
    "\n",
    "fill_non_workers(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filling up the Cultivator_Workers column :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E89i9ooa6pDD"
   },
   "outputs": [],
   "source": [
    "def fill_cultivator_workers(df):\n",
    "    for i in range(len(df)):\n",
    "        if null_values_filter(df,i,'Cultivator_Workers') == True:\n",
    "            if null_values_filter(df,i,'Workers') == null_values_filter(df,i,'Agricultural_Workers') == null_values_filter(df,i,'Household_Workers') == null_values_filter(df,i,'Other_Workers') == False:\n",
    "                df.loc[i,\"Cultivator_Workers\"] = int(df.loc[i,'Workers'] - (df.loc[i,'Agricultural_Workers'] + df.loc[i,'Household_Workers'] + df.loc[i,'Other_Workers']))\n",
    "\n",
    "fill_cultivator_workers(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filling up the Agricultural_Workers column :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dSlP7V_D5y6x"
   },
   "outputs": [],
   "source": [
    "def fill_agricultural_workers(df):\n",
    "    for i in range(len(df)):\n",
    "        if null_values_filter(df,i,'Agricultural_Workers') == True:\n",
    "            if null_values_filter(df,i,'Workers') == null_values_filter(df,i,'Cultivator_Workers') == null_values_filter(df,i,'Household_Workers') == null_values_filter(df,i,'Other_Workers') == False:\n",
    "                df.loc[i,\"Agricultural_Workers\"] = int(df.loc[i,'Workers'] - (df.loc[i,'Cultivator_Workers'] + df.loc[i,'Household_Workers'] + df.loc[i,'Other_Workers']))\n",
    "\n",
    "fill_agricultural_workers(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filling up the Household_Workers column :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H7174xVH7Vrx"
   },
   "outputs": [],
   "source": [
    "def fill_household_workers(df):\n",
    "    for i in range(len(df)):\n",
    "        if null_values_filter(df,i,'Household_Workers') == True:\n",
    "            if null_values_filter(df,i,'Workers') == null_values_filter(df,i,'Cultivator_Workers') == null_values_filter(df,i,'Agricultural_Workers') == null_values_filter(df,i,'Other_Workers') == False:\n",
    "                df.loc[i,\"Household_Workers\"] = int(df.loc[i,'Workers'] - (df.loc[i,'Cultivator_Workers'] + df.loc[i,'Agricultural_Workers'] + df.loc[i,'Other_Workers']))\n",
    "\n",
    "fill_household_workers(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filling up the Other_Workers column :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mjhUE5aI7Vdr"
   },
   "outputs": [],
   "source": [
    "def fill_other_workers(df):\n",
    "    for i in range(len(df)):\n",
    "        if null_values_filter(df,i,'Other_Workers') == True:\n",
    "            if null_values_filter(df,i,'Workers') == null_values_filter(df,i,'Cultivator_Workers') == null_values_filter(df,i,'Agricultural_Workers') == null_values_filter(df,i,'Household_Workers') == False:\n",
    "                df.loc[i,\"Other_Workers\"] = int(df.loc[i,'Workers'] - (df.loc[i,'Cultivator_Workers'] + df.loc[i,'Agricultural_Workers'] + df.loc[i,'Household_Workers']))\n",
    "\n",
    "fill_other_workers(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filling up the Hindus Column :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5gV3cW_U7VKs"
   },
   "outputs": [],
   "source": [
    "def fill_hindus(df):\n",
    "    for i in range(len(df)):\n",
    "        if null_values_filter(df,i,'Hindus') == True:\n",
    "            if null_values_filter(df,i,'Population') == null_values_filter(df,i,'Muslims') == null_values_filter(df,i,'Christians') == null_values_filter(df,i,'Sikhs') == null_values_filter(df,i,'Buddhists') == null_values_filter(df,i,'Jains') == null_values_filter(df,i,'Others_Religions') == null_values_filter(df,i,'Religion_Not_Stated') == False:\n",
    "                df.loc[i,'Hindus'] = int(df.loc[i,'Population'] - (df.loc[i,'Muslims'] + df.loc[i,'Christians'] + df.loc[i,'Sikhs'] + df.loc[i,'Buddhists'] + df.loc[i,'Jains'] + df.loc[i,'Others_Religions'] + df.loc[i,'Religion_Not_Stated']))\n",
    "\n",
    "fill_hindus(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filling up the Muslims column :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XT1A8C207VHH"
   },
   "outputs": [],
   "source": [
    "def fill_muslims(df):\n",
    "    for i in range(len(df)):\n",
    "        if null_values_filter(df,i,'Muslims') == True:\n",
    "            if null_values_filter(df,i,'Population') == null_values_filter(df,i,'Hindus') == null_values_filter(df,i,'Christians') == null_values_filter(df,i,'Sikhs') == null_values_filter(df,i,'Buddhists') == null_values_filter(df,i,'Jains') == null_values_filter(df,i,'Others_Religions') == null_values_filter(df,i,'Religion_Not_Stated') == False:\n",
    "                df.loc[i,'Muslims'] = int(df.loc[i,'Population'] - (df.loc[i,'Hindus'] + df.loc[i,'Christians'] + df.loc[i,'Sikhs'] + df.loc[i,'Buddhists'] + df.loc[i,'Jains'] + df.loc[i,'Others_Religions'] + df.loc[i,'Religion_Not_Stated']))\n",
    "\n",
    "fill_muslims(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filling up the Christians column :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yIPkFhHs8Co3"
   },
   "outputs": [],
   "source": [
    "def fill_christians(df):\n",
    "    for i in range(len(df)):\n",
    "        if null_values_filter(df,i,'Christians') == True:\n",
    "            if null_values_filter(df,i,'Population') == null_values_filter(df,i,'Hindus') == null_values_filter(df,i,'Muslims') == null_values_filter(df,i,'Sikhs') == null_values_filter(df,i,'Buddhists') == null_values_filter(df,i,'Jains') == null_values_filter(df,i,'Others_Religions') == null_values_filter(df,i,'Religion_Not_Stated') == False:\n",
    "                df.loc[i,'Christians'] = int(df.loc[i,'Population'] - (df.loc[i,'Hindus'] + df.loc[i,'Muslims'] + df.loc[i,'Sikhs'] + df.loc[i,'Buddhists'] + df.loc[i,'Jains'] + df.loc[i,'Others_Religions'] + df.loc[i,'Religion_Not_Stated']))\n",
    "\n",
    "fill_christians(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filling up the Sikhs column :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EDHn71kG8EdL"
   },
   "outputs": [],
   "source": [
    "def fill_sikhs(df):\n",
    "    for i in range(len(df)):\n",
    "        if null_values_filter(df,i,'Sikhs') == True:\n",
    "            if null_values_filter(df,i,'Population') == null_values_filter(df,i,'Hindus') == null_values_filter(df,i,'Muslims') == null_values_filter(df,i,'Christians') == null_values_filter(df,i,'Buddhists') == null_values_filter(df,i,'Jains') == null_values_filter(df,i,'Others_Religions') == null_values_filter(df,i,'Religion_Not_Stated') == False:\n",
    "                df.loc[i,'Sikhs'] = int(df.loc[i,'Population'] - (df.loc[i,'Hindus'] + df.loc[i,'Muslims'] + df.loc[i,'Christians'] + df.loc[i,'Buddhists'] + df.loc[i,'Jains'] + df.loc[i,'Others_Religions'] + df.loc[i,'Religion_Not_Stated']))\n",
    "\n",
    "fill_sikhs(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filling up the Buddhists column :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PPtXDP9v8IaB"
   },
   "outputs": [],
   "source": [
    "def fill_buddhists(df):\n",
    "    for i in range(len(df)):\n",
    "        if null_values_filter(df,i,'Buddhists') == True:\n",
    "            if null_values_filter(df,i,'Population') == null_values_filter(df,i,'Hindus') == null_values_filter(df,i,'Muslims') == null_values_filter(df,i,'Christians') == null_values_filter(df,i,'Sikhs') == null_values_filter(df,i,'Jains') == null_values_filter(df,i,'Others_Religions') == null_values_filter(df,i,'Religion_Not_Stated') == False:\n",
    "                df.loc[i,'Buddhists'] = int(df.loc[i,'Population'] - (df.loc[i,'Hindus'] + df.loc[i,'Muslims'] + df.loc[i,'Christians'] + df.loc[i,'Sikhs'] + df.loc[i,'Jains'] + df.loc[i,'Others_Religions'] + df.loc[i,'Religion_Not_Stated']))\n",
    "\n",
    "fill_buddhists(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filling up the Jains column :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lp9J6dSE8ETQ"
   },
   "outputs": [],
   "source": [
    "def fill_jains(df):\n",
    "    for i in range(len(df)):\n",
    "        if null_values_filter(df,i,'Jains') == True:\n",
    "            if null_values_filter(df,i,'Population') == null_values_filter(df,i,'Hindus') == null_values_filter(df,i,'Muslims') == null_values_filter(df,i,'Christians') == null_values_filter(df,i,'Sikhs') == null_values_filter(df,i,'Buddhists') == null_values_filter(df,i,'Others_Religions') == null_values_filter(df,i,'Religion_Not_Stated') == False:\n",
    "                df.loc[i,'Jains'] = int(df.loc[i,'Population'] - (df.loc[i,'Hindus'] + df.loc[i,'Muslims'] + df.loc[i,'Christians'] + df.loc[i,'Sikhs'] + df.loc[i,'Buddhists'] + df.loc[i,'Others_Religions'] + df.loc[i,'Religion_Not_Stated']))\n",
    "\n",
    "fill_jains(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filling up the Others_Religions column :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TV-D5A548ClN"
   },
   "outputs": [],
   "source": [
    "def fill_others_religions(df):\n",
    "    for i in range(len(df)):\n",
    "        if null_values_filter(df,i,'Others_Religions') == True:\n",
    "            if null_values_filter(df,i,'Population') == null_values_filter(df,i,'Hindus') == null_values_filter(df,i,'Muslims') == null_values_filter(df,i,'Christians') == null_values_filter(df,i,'Sikhs') == null_values_filter(df,i,'Buddhists') == null_values_filter(df,i,'Jains') == null_values_filter(df,i,'Religion_Not_Stated') == False:\n",
    "                df.loc[i,'Others_Religions'] = int(df.loc[i,'Population'] - (df.loc[i,'Hindus'] + df.loc[i,'Muslims'] + df.loc[i,'Christians'] + df.loc[i,'Sikhs'] + df.loc[i,'Buddhists'] + df.loc[i,'Jains'] + df.loc[i,'Religion_Not_Stated']))\n",
    "\n",
    "fill_others_religions(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filling up the Religion_Not_Stated column :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c-i6VN_28V54"
   },
   "outputs": [],
   "source": [
    "def fill_religion_not_stated(df):\n",
    "    for i in range(len(df)):\n",
    "        if null_values_filter(df,i,'Religion_Not_Stated') == True:\n",
    "            if null_values_filter(df,i,'Population') == null_values_filter(df,i,'Hindus') == null_values_filter(df,i,'Muslims') == null_values_filter(df,i,'Christians') == null_values_filter(df,i,'Sikhs') == null_values_filter(df,i,'Buddhists') == null_values_filter(df,i,'Jains') == null_values_filter(df,i,'Others_Religions') == False:\n",
    "                df.loc[i,'Religion_Not_Stated'] = int(df.loc[i,'Population'] - (df.loc[i,'Hindus'] + df.loc[i,'Muslims'] + df.loc[i,'Christians'] + df.loc[i,'Sikhs'] + df.loc[i,'Buddhists'] + df.loc[i,'Jains'] + df.loc[i,'Others_Religions']))\n",
    "\n",
    "fill_religion_not_stated(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filling up the Households_Rural column :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sNgJyDSC8Vnb"
   },
   "outputs": [],
   "source": [
    "def fill_households_rural(df):\n",
    "    for i in range(len(df)):\n",
    "        if null_values_filter(df,i,'Households_Rural') == True:\n",
    "            if null_values_filter(df,i,'Households') == null_values_filter(df,i,'Households_Urban') == False:\n",
    "                df.loc[i,'Households_Rural'] = int(df.loc[i,\"Households\"] - df.loc[i,'Households_Urban'])\n",
    "\n",
    "fill_households_rural(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filling up the Households_Urban column :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sAXt29cP8chV"
   },
   "outputs": [],
   "source": [
    "def fill_households_urban(df):\n",
    "    for i in range(len(df)):\n",
    "        if null_values_filter(df,i,'Households_Urban') == True:\n",
    "            if null_values_filter(df,i,'Households') == null_values_filter(df,i,'Households_Rural') == False:\n",
    "                df.loc[i,'Households_Urban'] = int(df.loc[i,\"Households\"] - df.loc[i,'Households_Rural'])\n",
    "\n",
    "fill_households_urban(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filling up the Households column :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CxNa8oG78cNd"
   },
   "outputs": [],
   "source": [
    "def fill_households(df):\n",
    "    for i in range(len(df)):\n",
    "        if null_values_filter(df,i,'Households') == True:\n",
    "            if null_values_filter(df,i,'Households_Urban') == null_values_filter(df,i,'Households_Rural') == False:\n",
    "                df.loc[i,'Households'] = int(df.loc[i,\"Households_Urban\"] + df.loc[i,'Households_Rural'])\n",
    "\n",
    "fill_households(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filling up the Literate Education column :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W3joZ-qK8cJ-"
   },
   "outputs": [],
   "source": [
    "def fill_literate_education(df):\n",
    "    for i in range(len(df)):\n",
    "        if null_values_filter(df,i,'Literate_Education') == True:\n",
    "            if null_values_filter(df,i,'Below_Primary_Education') == null_values_filter(df,i,'Primary_Education') == null_values_filter(df,i,'Middle_Education') == null_values_filter(df,i,'Secondary_Education') == null_values_filter(df,i,'Higher_Education') == null_values_filter(df,i,'Graduate_Education') == null_values_filter(df,i,'Other_Education') == False:\n",
    "                df.loc[i,'Literate_Education'] = df.loc[i,'Below_Primary_Education'] + df.loc[i,'Primary_Education'] + df.loc[i,'Middle_Education'] + df.loc[i,'Secondary_Education'] + df.loc[i,'Higher_Education'] + df.loc[i,'Graduate_Education'] + df.loc[i,'Other_Education']\n",
    "            elif null_values_filter(df,i,'Illiterate_Education') == null_values_filter(df,i,'Total_Education') == False:\n",
    "                df.loc[i,'Literate_Education'] = int(df.loc[i,'Total_Education'] - df.loc[i,'Illiterate_Education'])\n",
    "\n",
    "fill_literate_education(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filling up the Below_Primary_Education column :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XOHM1e4m8rMz"
   },
   "outputs": [],
   "source": [
    "def fill_below_primary_education(df):\n",
    "    for i in range(len(df)):\n",
    "        if null_values_filter(df,i,'Below_Primary_Education') == True:\n",
    "            if null_values_filter(df,i,'Literate_Education') == null_values_filter(df,i,'Primary_Education') == null_values_filter(df,i,'Middle_Education') == null_values_filter(df,i,'Secondary_Education') == null_values_filter(df,i,'Higher_Education') == null_values_filter(df,i,'Graduate_Education') == null_values_filter(df,i,'Other_Education') == False:\n",
    "                df.loc[i,'Below_Primary_Education'] = int(df.loc[i,'Literate_Education'] - (df.loc[i,'Primary_Education'] + df.loc[i,'Middle_Education'] + df.loc[i,'Secondary_Education'] + df.loc[i,'Higher_Education'] + df.loc[i,'Graduate_Education'] + df.loc[i,'Other_Education']))\n",
    "\n",
    "fill_below_primary_education(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filling up the Primary_Education column :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TxIs7hDf8s8J"
   },
   "outputs": [],
   "source": [
    "def fill_primary_education(df):\n",
    "    for i in range(len(df)):\n",
    "        if null_values_filter(df,i,'Primary_Education') == True:\n",
    "            if null_values_filter(df,i,'Literate_Education') == null_values_filter(df,i,'Below_Primary_Education') == null_values_filter(df,i,'Middle_Education') == null_values_filter(df,i,'Secondary_Education') == null_values_filter(df,i,'Higher_Education') == null_values_filter(df,i,'Graduate_Education') == null_values_filter(df,i,'Other_Education') == False:\n",
    "                df.loc[i,'Primary_Education'] = int(df.loc[i,'Literate_Education'] - (df.loc[i,'Below_Primary_Education'] + df.loc[i,'Middle_Education'] + df.loc[i,'Secondary_Education'] + df.loc[i,'Higher_Education'] + df.loc[i,'Graduate_Education'] + df.loc[i,'Other_Education']))\n",
    "\n",
    "fill_primary_education(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filling up the Middle_Education column :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3W744Fou8szS"
   },
   "outputs": [],
   "source": [
    "def fill_middle_education(df):\n",
    "    for i in range(len(df)):\n",
    "        if null_values_filter(df,i,'Middle_Education') == True:\n",
    "            if null_values_filter(df,i,'Literate_Education') == null_values_filter(df,i,'Below_Primary_Education') == null_values_filter(df,i,'Primary_Education') == null_values_filter(df,i,'Secondary_Education') == null_values_filter(df,i,'Higher_Education') == null_values_filter(df,i,'Graduate_Education') == null_values_filter(df,i,'Other_Education') == False:\n",
    "                df.loc[i,'Middle_Education'] = int(df.loc[i,'Literate_Education'] - (df.loc[i,'Below_Primary_Education'] + df.loc[i,'Primary_Education'] + df.loc[i,'Secondary_Education'] + df.loc[i,'Higher_Education'] + df.loc[i,'Graduate_Education'] + df.loc[i,'Other_Education']))\n",
    "\n",
    "fill_middle_education(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filling up the Secondary_Education column :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YUUPPagH8rJW"
   },
   "outputs": [],
   "source": [
    "def fill_secondary_education(df):\n",
    "    for i in range(len(df)):\n",
    "        if null_values_filter(df,i,'Secondary_Education') == True:\n",
    "            if null_values_filter(df,i,'Literate_Education') == null_values_filter(df,i,'Below_Primary_Education') == null_values_filter(df,i,'Primary_Education') == null_values_filter(df,i,'Middle_Education') == null_values_filter(df,i,'Higher_Education') == null_values_filter(df,i,'Graduate_Education') == null_values_filter(df,i,'Other_Education') == False:\n",
    "                df.loc[i,'Secondary_Education'] = int(df.loc[i,'Literate_Education'] - (df.loc[i,'Below_Primary_Education'] + df.loc[i,'Primary_Education'] + df.loc[i,'Middle_Education'] + df.loc[i,'Higher_Education'] + df.loc[i,'Graduate_Education'] + df.loc[i,'Other_Education']))\n",
    "\n",
    "fill_secondary_education(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filling up the Higher_Education column :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DfX5K68L5y2x"
   },
   "outputs": [],
   "source": [
    "def fill_higher_education(df):\n",
    "    for i in range(len(df)):\n",
    "        if null_values_filter(df,i,'Higher_Education') == True:\n",
    "            if null_values_filter(df,i,'Literate_Education') == null_values_filter(df,i,'Below_Primary_Education') == null_values_filter(df,i,'Primary_Education') == null_values_filter(df,i,'Middle_Education') == null_values_filter(df,i,'Secondary_Education') == null_values_filter(df,i,'Graduate_Education') == null_values_filter(df,i,'Other_Education') == False:\n",
    "                df.loc[i,'Higher_Education'] = int(df.loc[i,'Literate_Education'] - (df.loc[i,'Below_Primary_Education'] + df.loc[i,'Primary_Education'] + df.loc[i,'Middle_Education'] + df.loc[i,'Secondary_Education'] + df.loc[i,'Graduate_Education'] + df.loc[i,'Other_Education']))\n",
    "\n",
    "fill_higher_education(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filling up the Graduate_Education column :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lABNxdiYNZ8f"
   },
   "outputs": [],
   "source": [
    "def fill_graduate_education(df):\n",
    "    for i in range(len(df)):\n",
    "        if null_values_filter(df,i,'Graduate_Education') == True:\n",
    "            if null_values_filter(df,i,'Literate_Education') == null_values_filter(df,i,'Below_Primary_Education') == null_values_filter(df,i,'Primary_Education') == null_values_filter(df,i,'Middle_Education') == null_values_filter(df,i,'Secondary_Education') == null_values_filter(df,i,'Higher_Education') == null_values_filter(df,i,'Other_Education') == False:\n",
    "                df.loc[i,'Graduate_Education'] = int(df.loc[i,'Literate_Education'] - (df.loc[i,'Below_Primary_Education'] + df.loc[i,'Primary_Education'] + df.loc[i,'Middle_Education'] + df.loc[i,'Secondary_Education'] + df.loc[i,'Higher_Education'] + df.loc[i,'Other_Education']))\n",
    "\n",
    "fill_graduate_education(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filling up the Other_Education column :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OqeB2A_qNdMJ"
   },
   "outputs": [],
   "source": [
    "def fill_other_education(df):\n",
    "    for i in range(len(df)):\n",
    "        if null_values_filter(df,i,'Other_Education') == True:\n",
    "            if null_values_filter(df,i,'Literate_Education') == null_values_filter(df,i,'Below_Primary_Education') == null_values_filter(df,i,'Primary_Education') == null_values_filter(df,i,'Middle_Education') == null_values_filter(df,i,'Secondary_Education') == null_values_filter(df,i,'Higher_Education') == null_values_filter(df,i,'Graduate_Education') == False:\n",
    "                df.loc[i,'Other_Education'] = int(df.loc[i,'Literate_Education'] - (df.loc[i,'Below_Primary_Education'] + df.loc[i,'Primary_Education'] + df.loc[i,'Middle_Education'] + df.loc[i,'Secondary_Education'] + df.loc[i,'Higher_Education'] + df.loc[i,'Graduate_Education']))\n",
    "\n",
    "fill_other_education(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filling up the Illiterate_Education column :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "meYci95lNdIy"
   },
   "outputs": [],
   "source": [
    "def fill_illiterate_education(df):\n",
    "    for i in range(len(df)):\n",
    "        if null_values_filter(df,i,'Illiterate_Education') == True:\n",
    "            if null_values_filter(df,i,'Literate_Education') == null_values_filter(df,i,'Total_Education') == False:\n",
    "                df.loc[i,'Illiterate_Education'] = int(df.loc[i,'Total_Education'] - df.loc[i,'Literate_Education'])\n",
    "\n",
    "fill_illiterate_education(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filling up the Total_Education column :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f25xQD9VNdFA"
   },
   "outputs": [],
   "source": [
    "def fill_total_education(df):\n",
    "    for i in range(len(df)):\n",
    "        if null_values_filter(df,i,'Total_Education') == True:\n",
    "            if null_values_filter(df,i,'Literate_Education') == null_values_filter(df,i,'Illiterate_Education') == False:\n",
    "                df.loc[i,'Total_Education'] = int(df.loc[i,'Literate_Education'] + df.loc[i,'Illiterate_Education'])\n",
    "\n",
    "fill_total_education(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filling up the Young_and_Adult column :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6e6XX7hXNZ4r"
   },
   "outputs": [],
   "source": [
    "def fill_young_and_adult(df):\n",
    "    for i in range(len(df)):\n",
    "        if null_values_filter(df,i,'Young_and_Adult') == True:\n",
    "            if null_values_filter(df,i,'Population') == null_values_filter(df,i,'Middle_Aged') == null_values_filter(df,i,'Senior_Citizen') == null_values_filter(df,i,'Age_Not_Stated') == False:\n",
    "                df.loc[i,'Young_and_Adult'] = int(df.loc[i,'Population'] - (df.loc[i,'Middle_Aged'] + df.loc[i,'Senior_Citizen'] + df.loc[i,'Age_Not_Stated']))\n",
    "\n",
    "fill_young_and_adult(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filling up the Middle_Aged column :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ru52Bh7ONZ1C"
   },
   "outputs": [],
   "source": [
    "def fill_middle_aged(df):\n",
    "    for i in range(len(df)):\n",
    "        if null_values_filter(df,i,'Middle_Aged') == True:\n",
    "            if null_values_filter(df,i,'Population') == null_values_filter(df,i,'Young_and_Adult') == null_values_filter(df,i,'Senior_Citizen') == null_values_filter(df,i,'Age_Not_Stated') == False:\n",
    "                df.loc[i,'Middle_Aged'] = int(df.loc[i,'Population'] - (df.loc[i,'Young_and_Adult'] + df.loc[i,'Senior_Citizen'] + df.loc[i,'Age_Not_Stated']))\n",
    "\n",
    "fill_middle_aged(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filling up the Senior_Citizen column :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Brs_o1m_Nymm"
   },
   "outputs": [],
   "source": [
    "def fill_senior_citizen(df):\n",
    "    for i in range(len(df)):\n",
    "        if null_values_filter(df,i,'Senior_Citizen') == True:\n",
    "            if null_values_filter(df,i,'Population') == null_values_filter(df,i,'Young_and_Adult') == null_values_filter(df,i,'Middle_Aged') == null_values_filter(df,i,'Age_Not_Stated') == False:\n",
    "                df.loc[i,'Senior_Citizen'] = int(df.loc[i,'Population'] - (df.loc[i,'Young_and_Adult'] + df.loc[i,'Middle_Aged'] + df.loc[i,'Age_Not_Stated']))\n",
    "\n",
    "fill_senior_citizen(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filling up the Senior_Citizen column :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mVw1pqRmNyjH"
   },
   "outputs": [],
   "source": [
    "def fill_age_not_stated(df):\n",
    "    for i in range(len(df)):\n",
    "        if null_values_filter(df,i,'Age_Not_Stated') == True:\n",
    "            if null_values_filter(df,i,'Population') == null_values_filter(df,i,'Young_and_Adult') == null_values_filter(df,i,'Middle_Aged') == null_values_filter(df,i,'Senior_Citizen') == False:\n",
    "                df.loc[i,'Age_Not_Stated'] = int(df.loc[i,'Population'] - (df.loc[i,'Young_and_Adult'] + df.loc[i,'Middle_Aged'] + df.loc[i,'Senior_Citizen']))\n",
    "\n",
    "fill_age_not_stated(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filling up the Household_size_1_person_Households column :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o2Cl28bONyZE"
   },
   "outputs": [],
   "source": [
    "def fill_household_size_1_person_households(df):\n",
    "    for i in range(len(df)):\n",
    "        if null_values_filter(df,i,'Household_size_1_person_Households') == True:\n",
    "            if null_values_filter(df,i,'Household_size_1_to_2_persons') == null_values_filter(df,i,'Household_size_2_persons_Households') == False:\n",
    "                df.loc[i,'Household_size_1_person_Households'] = int(df.loc[i,'Household_size_1_to_2_persons'] - df.loc[i,'Household_size_2_persons_Households'])\n",
    "\n",
    "fill_household_size_1_person_households(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filling up the Household_size_2_persons_Households column :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6VwJqaWLNyOL"
   },
   "outputs": [],
   "source": [
    "def fill_household_size_2_persons_households(df):\n",
    "    for i in range(len(df)):\n",
    "        if null_values_filter(df,i,'Household_size_2_persons_Households') == True:\n",
    "            if null_values_filter(df,i,'Household_size_1_to_2_persons') == null_values_filter(df,i,'Household_size_1_person_Households') == False:\n",
    "                df.loc[i,'Household_size_2_persons_Households'] = int(df.loc[i,'Household_size_1_to_2_persons'] - df.loc[i,'Household_size_1_person_Households'])\n",
    "\n",
    "fill_household_size_2_persons_households(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filling up the Household_size_1_to_2_persons column :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_oWV_53ZOBWL"
   },
   "outputs": [],
   "source": [
    "def fill_household_size_1_to_2_persons(df):\n",
    "    for i in range(len(df)):\n",
    "        if null_values_filter(df,i,'Household_size_1_to_2_persons') == True:\n",
    "            if null_values_filter(df,i,'Household_size_1_person_Households') == null_values_filter(df,i,'Household_size_2_persons_Households') == False:\n",
    "                df.loc[i,'Household_size_1_to_2_persons'] = int(df.loc[i,'Household_size_1_person_Households'] + df.loc[i,'Household_size_2_persons_Households'])\n",
    "\n",
    "fill_household_size_1_to_2_persons(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filling up the Household_size_3_persons_Households column :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "USPkp4uaOAyB"
   },
   "outputs": [],
   "source": [
    "def fill_household_size_3_persons_households(df):\n",
    "    for i in range(len(df)):\n",
    "        if null_values_filter(df,i,'Household_size_3_persons_Households') == True:\n",
    "            if null_values_filter(df,i,'Household_size_4_persons_Households') ==  null_values_filter(df,i,'Household_size_5_persons_Households') == null_values_filter(df,i,'Household_size_3_to_5_persons_Households') == False:\n",
    "                df.loc[i,'Household_size_3_persons_Households'] = int(df.loc[i,'Household_size_3_to_5_persons_Households'] - (df.loc[i,'Household_size_4_persons_Households'] + df.loc[i,'Household_size_5_persons_Households']))\n",
    "\n",
    "fill_household_size_3_persons_households(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filling up the Household_size_4_persons_Households column :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YEuR-AEMOJkB"
   },
   "outputs": [],
   "source": [
    "def fill_household_size_4_persons_households(df):\n",
    "    for i in range(len(df)):\n",
    "        if null_values_filter(df,i,'Household_size_4_persons_Households') == True:\n",
    "            if null_values_filter(df,i,'Household_size_3_persons_Households') ==  null_values_filter(df,i,'Household_size_5_persons_Households') == null_values_filter(df,i,'Household_size_3_to_5_persons_Households') == False:\n",
    "                df.loc[i,'Household_size_4_persons_Households'] = int(df.loc[i,'Household_size_3_to_5_persons_Households'] - (df.loc[i,'Household_size_3_persons_Households'] + df.loc[i,'Household_size_5_persons_Households']))\n",
    "\n",
    "fill_household_size_4_persons_households(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filling up the Household_size_5_persons_Households column :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dmppR5GWOJUK"
   },
   "outputs": [],
   "source": [
    "def fill_household_size_5_persons_households(df):\n",
    "    for i in range(len(df)):\n",
    "        if null_values_filter(df,i,'Household_size_5_persons_Households') == True:\n",
    "            if null_values_filter(df,i,'Household_size_3_persons_Households') ==  null_values_filter(df,i,'Household_size_4_persons_Households') == null_values_filter(df,i,'Household_size_3_to_5_persons_Households') == False:\n",
    "                df.loc[i,'Household_size_5_persons_Households'] = int(df.loc[i,'Household_size_3_to_5_persons_Households'] - (df.loc[i,'Household_size_3_persons_Households'] + df.loc[i,'Household_size_4_persons_Households']))\n",
    "\n",
    "fill_household_size_5_persons_households(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filling up the Household_size_3_to_5_persons_Households column :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GiaRWAozOJKf"
   },
   "outputs": [],
   "source": [
    "def fill_household_size_3_to_5_persons_households(df):\n",
    "    for i in range(len(df)):\n",
    "        if null_values_filter(df,i,'Household_size_3_to_5_persons_Households') == True:\n",
    "            if null_values_filter(df,i,'Household_size_3_persons_Households') == null_values_filter(df,i,'Household_size_4_persons_Households') == null_values_filter(df,i,'Household_size_5_persons_Households') == False:\n",
    "                df.loc[i,'Household_size_3_to_5_persons_Households'] = int(df.loc[i,'Household_size_3_persons_Households'] + df.loc[i,'Household_size_4_persons_Households'] + df.loc[i,'Household_size_5_persons_Households'])\n",
    "\n",
    "fill_household_size_3_to_5_persons_households(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filling up the Power_Parity_Rs_45000_90000 column :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PhaJOPyPOI_B"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def fill_power_parity_rs_45000_90000(df):\n",
    "    for i in range(len(df)):\n",
    "        if null_values_filter(df,i,'Power_Parity_Rs_45000_90000') == True:\n",
    "            if null_values_filter(df,i,'Power_Parity_Rs_90000_150000') == null_values_filter(df,i,'Power_Parity_Rs_45000_150000') == False:\n",
    "                df.loc[i,'Power_Parity_Rs_45000_90000'] = int(df.loc[i,'Power_Parity_Rs_45000_150000'] - df.loc[i,'Power_Parity_Rs_90000_150000'])\n",
    "            elif null_values_filter(df,i,'Total_Power_Parity') == null_values_filter(df,i,'Power_Parity_Less_than_Rs_45000') == null_values_filter(df,i,'Power_Parity_Rs_90000_150000') == null_values_filter(df,i,'Power_Parity_Rs_150000_240000') == null_values_filter(df,i,'Power_Parity_Rs_240000_330000') == null_values_filter(df,i,'Power_Parity_Rs_330000_425000') == null_values_filter(df,i,'Power_Parity_Rs_425000_545000') == null_values_filter(df,i,'Power_Parity_Above_Rs_545000') == False:\n",
    "                df.loc[i,'Power_Parity_Rs_45000_90000'] = int(df.loc[i,'Total_Power_Parity'] - (df.loc[i,'Power_Parity_Less_than_Rs_45000'] + df.loc[i,'Power_Parity_Rs_90000_150000'] + df.loc[i,'Power_Parity_Rs_150000_240000'] + df.loc[i,'Power_Parity_Rs_240000_330000'] + df.loc[i,'Power_Parity_Rs_330000_425000'] + df.loc[i,'Power_Parity_Rs_425000_545000'] + df.loc[i,'Power_Parity_Above_Rs_545000']))\n",
    "\n",
    "fill_power_parity_rs_45000_90000(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filling up the Power_Parity_Rs_90000_150000 column :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lOcIsqfEOAlO"
   },
   "outputs": [],
   "source": [
    "def fill_power_parity_rs_90000_150000(df):\n",
    "    for i in range(len(df)):\n",
    "        if null_values_filter(df,i,'Power_Parity_Rs_90000_150000') == True:\n",
    "            if null_values_filter(df,i,'Power_Parity_Rs_45000_150000') == null_values_filter(df,i,'Power_Parity_Rs_45000_90000') == False:\n",
    "                df.loc[i,'Power_Parity_Rs_90000_150000'] = int(df.loc[i,'Power_Parity_Rs_45000_150000'] - df.loc[i,'Power_Parity_Rs_45000_90000'])\n",
    "            elif null_values_filter(df,i,'Total_Power_Parity') == null_values_filter(df,i,'Power_Parity_Less_than_Rs_45000') == null_values_filter(df,i,'Power_Parity_Rs_45000_90000') == null_values_filter(df,i,'Power_Parity_Rs_150000_240000') == null_values_filter(df,i,'Power_Parity_Rs_240000_330000') == null_values_filter(df,i,'Power_Parity_Rs_330000_425000') == null_values_filter(df,i,'Power_Parity_Rs_425000_545000') == null_values_filter(df,i,'Power_Parity_Above_Rs_545000') == False:\n",
    "                df.loc[i,'Power_Parity_Rs_90000_150000'] = int(df.loc[i,'Total_Power_Parity'] - (df.loc[i,'Power_Parity_Less_than_Rs_45000'] + df.loc[i,'Power_Parity_Rs_45000_90000'] + df.loc[i,'Power_Parity_Rs_150000_240000'] + df.loc[i,'Power_Parity_Rs_240000_330000'] + df.loc[i,'Power_Parity_Rs_330000_425000'] + df.loc[i,'Power_Parity_Rs_425000_545000'] + df.loc[i,'Power_Parity_Above_Rs_545000']))\n",
    "\n",
    "fill_power_parity_rs_90000_150000(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filling up the Power_Parity_Rs_45000_150000 column :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7WIUpa9nOAWH"
   },
   "outputs": [],
   "source": [
    "def fill_power_parity_rs_45000_150000(df):\n",
    "    for i in range(len(df)):\n",
    "        if null_values_filter(df,i,'Power_Parity_Rs_45000_150000') == True:\n",
    "            if null_values_filter(df,i,'Power_Parity_Rs_45000_90000') == null_values_filter(df,i,'Power_Parity_Rs_90000_150000') == False:\n",
    "                df.loc[i,'Power_Parity_Rs_45000_150000'] = int(df.loc[i,'Power_Parity_Rs_45000_90000'] + df.loc[i,'Power_Parity_Rs_90000_150000'])\n",
    "            elif null_values_filter(df,i,'Total_Power_Parity') == null_values_filter(df,i,'Power_Parity_Less_than_Rs_45000') == null_values_filter(df,i,'Power_Parity_Rs_150000_240000') == null_values_filter(df,i,'Power_Parity_Rs_240000_330000') == null_values_filter(df,i,'Power_Parity_Rs_330000_425000') == null_values_filter(df,i,'Power_Parity_Rs_425000_545000') == null_values_filter(df,i,'Power_Parity_Above_Rs_545000') == False:\n",
    "                df.loc[i,'Power_Parity_Rs_45000_150000'] = int(df.loc[i,'Total_Power_Parity'] - (df.loc[i,'Power_Parity_Less_than_Rs_45000'] + df.loc[i,'Power_Parity_Rs_150000_240000'] + df.loc[i,'Power_Parity_Rs_240000_330000'] + df.loc[i,'Power_Parity_Rs_330000_425000'] + df.loc[i,'Power_Parity_Rs_425000_545000'] + df.loc[i,'Power_Parity_Above_Rs_545000']))\n",
    "\n",
    "fill_power_parity_rs_45000_150000(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filling up the Power_Parity_Rs_150000_240000 column :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e6o7N4MXOfzD"
   },
   "outputs": [],
   "source": [
    "def fill_power_parity_rs_150000_240000(df):\n",
    "    for i in range(len(df)):\n",
    "        if null_values_filter(df,i,'Power_Parity_Rs_150000_240000') == True:\n",
    "            if null_values_filter(df,i,'Power_Parity_Rs_240000_330000') == null_values_filter(df,i,'Power_Parity_Rs_150000_330000') == False:\n",
    "                df.loc[i,'Power_Parity_Rs_150000_240000'] = int(df.loc[i,'Power_Parity_Rs_150000_330000'] - df.loc[i,'Power_Parity_Rs_240000_330000'])\n",
    "            elif null_values_filter(df,i,'Total_Power_Parity') == null_values_filter(df,i,'Power_Parity_Less_than_Rs_45000') == null_values_filter(df,i,'Power_Parity_Rs_45000_90000') == null_values_filter(df,i,'Power_Parity_Rs_90000_150000') == null_values_filter(df,i,'Power_Parity_Rs_240000_330000') == null_values_filter(df,i,'Power_Parity_Rs_330000_425000') == null_values_filter(df,i,'Power_Parity_Rs_425000_545000') == null_values_filter(df,i,'Power_Parity_Above_Rs_545000') == False:\n",
    "                df.loc[i,'Power_Parity_Rs_150000_240000'] = int(df.loc[i,'Total_Power_Parity'] - (df.loc[i,'Power_Parity_Less_than_Rs_45000'] + df.loc[i,'Power_Parity_Rs_45000_90000'] + df.loc[i,'Power_Parity_Rs_90000_150000'] + df.loc[i,'Power_Parity_Rs_240000_330000'] + df.loc[i,'Power_Parity_Rs_330000_425000'] + df.loc[i,'Power_Parity_Rs_425000_545000'] + df.loc[i,'Power_Parity_Above_Rs_545000']))\n",
    "\n",
    "fill_power_parity_rs_150000_240000(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filling up the Power_Parity_Rs_240000_330000 column :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M7wKcDkAOfkZ"
   },
   "outputs": [],
   "source": [
    "def fill_power_parity_rs_240000_330000(df):\n",
    "    for i in range(len(df)):\n",
    "        if null_values_filter(df,i,'Power_Parity_Rs_240000_330000') == True:\n",
    "            if null_values_filter(df,i,'Power_Parity_Rs_150000_240000') == null_values_filter(df,i,'Power_Parity_Rs_150000_330000') == False:\n",
    "                df.loc[i,'Power_Parity_Rs_240000_330000'] = int(df.loc[i,'Power_Parity_Rs_150000_330000'] - df.loc[i,'Power_Parity_Rs_150000_240000'])\n",
    "            elif null_values_filter(df,i,'Total_Power_Parity') == null_values_filter(df,i,'Power_Parity_Less_than_Rs_45000') == null_values_filter(df,i,'Power_Parity_Rs_45000_90000') == null_values_filter(df,i,'Power_Parity_Rs_90000_150000') == null_values_filter(df,i,'Power_Parity_Rs_150000_240000') == null_values_filter(df,i,'Power_Parity_Rs_330000_425000') == null_values_filter(df,i,'Power_Parity_Rs_425000_545000') == null_values_filter(df,i,'Power_Parity_Above_Rs_545000') == False:\n",
    "                df.loc[i,'Power_Parity_Rs_240000_330000'] = int(df.loc[i,'Total_Power_Parity'] - (df.loc[i,'Power_Parity_Less_than_Rs_45000'] + df.loc[i,'Power_Parity_Rs_45000_90000'] + df.loc[i,'Power_Parity_Rs_90000_150000'] + df.loc[i,'Power_Parity_Rs_150000_240000'] + df.loc[i,'Power_Parity_Rs_330000_425000'] + df.loc[i,'Power_Parity_Rs_425000_545000'] + df.loc[i,'Power_Parity_Above_Rs_545000']))\n",
    "\n",
    "fill_power_parity_rs_240000_330000(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filling up the Power_Parity_Rs_150000_330000 column :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NLJ8c7h7OoUb"
   },
   "outputs": [],
   "source": [
    "def fill_power_parity_rs_150000_330000(df):\n",
    "    for i in range(len(df)):\n",
    "        if null_values_filter(df,i,'Power_Parity_Rs_150000_330000') == True:\n",
    "            if null_values_filter(df,i,'Power_Parity_Rs_150000_240000') == null_values_filter(df,i,'Power_Parity_Rs_240000_330000') == False:\n",
    "                df.loc[i,'Power_Parity_Rs_150000_330000'] = int(df.loc[i,'Power_Parity_Rs_150000_240000'] + df.loc[i,'Power_Parity_Rs_240000_330000'])\n",
    "            elif null_values_filter(df,i,'Total_Power_Parity') == null_values_filter(df,i,'Power_Parity_Less_than_Rs_45000') == null_values_filter(df,i,'Power_Parity_Rs_45000_90000') == null_values_filter(df,i,'Power_Parity_Rs_90000_150000') == null_values_filter(df,i,'Power_Parity_Rs_330000_425000') == null_values_filter(df,i,'Power_Parity_Rs_425000_545000') == null_values_filter(df,i,'Power_Parity_Above_Rs_545000') == False:\n",
    "                df.loc[i,'Power_Parity_Rs_150000_330000'] = int(df.loc[i,'Total_Power_Parity'] - (df.loc[i,'Power_Parity_Less_than_Rs_45000'] + df.loc[i,'Power_Parity_Rs_45000_90000'] + df.loc[i,'Power_Parity_Rs_90000_150000'] + df.loc[i,'Power_Parity_Rs_330000_425000'] + df.loc[i,'Power_Parity_Rs_425000_545000'] + df.loc[i,'Power_Parity_Above_Rs_545000']))\n",
    "\n",
    "fill_power_parity_rs_150000_330000(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filling up the Power_Parity_Rs_330000_425000 column :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DCIJ310JOoQ7"
   },
   "outputs": [],
   "source": [
    "def fill_power_parity_rs_330000_425000(df):\n",
    "    for i in range(len(df)):\n",
    "        if null_values_filter(df,i,'Power_Parity_Rs_330000_425000') == True:\n",
    "            if null_values_filter(df,i,'Power_Parity_Rs_425000_545000') == null_values_filter(df,i,'Power_Parity_Rs_330000_545000') == False:\n",
    "                df.loc[i,'Power_Parity_Rs_330000_425000'] = int(df.loc[i,'Power_Parity_Rs_330000_545000'] - df.loc[i,'Power_Parity_Rs_425000_545000'])\n",
    "            elif null_values_filter(df,i,'Total_Power_Parity') == null_values_filter(df,i,'Power_Parity_Less_than_Rs_45000') == null_values_filter(df,i,'Power_Parity_Rs_45000_90000') == null_values_filter(df,i,'Power_Parity_Rs_90000_150000') == null_values_filter(df,i,'Power_Parity_Rs_150000_240000') == null_values_filter(df,i,'Power_Parity_Rs_240000_330000') == null_values_filter(df,i,'Power_Parity_Rs_425000_545000') == null_values_filter(df,i,'Power_Parity_Above_Rs_545000') == False:\n",
    "                df.loc[i,'Power_Parity_Rs_330000_425000'] = int(df.loc[i,'Total_Power_Parity'] - (df.loc[i,'Power_Parity_Less_than_Rs_45000'] + df.loc[i,'Power_Parity_Rs_45000_90000'] + df.loc[i,'Power_Parity_Rs_90000_150000'] + df.loc[i,'Power_Parity_Rs_150000_240000'] + df.loc[i,'Power_Parity_Rs_240000_330000'] + df.loc[i,'Power_Parity_Rs_425000_545000'] + df.loc[i,'Power_Parity_Above_Rs_545000']))\n",
    "\n",
    "fill_power_parity_rs_330000_425000(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filling up the Power_Parity_Rs_425000_545000 column :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wXNDe7KqOoNU"
   },
   "outputs": [],
   "source": [
    "def fill_power_parity_rs_425000_545000(df):\n",
    "    for i in range(len(df)):\n",
    "        if null_values_filter(df,i,'Power_Parity_Rs_425000_545000') == True:\n",
    "            if null_values_filter(df,i,'Power_Parity_Rs_330000_425000') == null_values_filter(df,i,'Power_Parity_Rs_330000_545000') == False:\n",
    "                df.loc[i,'Power_Parity_Rs_425000_545000'] = int(df.loc[i,'Power_Parity_Rs_330000_545000'] - df.loc[i,'Power_Parity_Rs_330000_425000'])\n",
    "            elif null_values_filter(df,i,'Total_Power_Parity') == null_values_filter(df,i,'Power_Parity_Less_than_Rs_45000') == null_values_filter(df,i,'Power_Parity_Rs_45000_90000') == null_values_filter(df,i,'Power_Parity_Rs_90000_150000') == null_values_filter(df,i,'Power_Parity_Rs_150000_240000') == null_values_filter(df,i,'Power_Parity_Rs_240000_330000') == null_values_filter(df,i,'Power_Parity_Rs_330000_425000') == null_values_filter(df,i,'Power_Parity_Above_Rs_545000') == False:\n",
    "                df.loc[i,'Power_Parity_Rs_425000_545000'] = int(df.loc[i,'Total_Power_Parity'] - (df.loc[i,'Power_Parity_Less_than_Rs_45000'] + df.loc[i,'Power_Parity_Rs_45000_90000'] + df.loc[i,'Power_Parity_Rs_90000_150000'] + df.loc[i,'Power_Parity_Rs_150000_240000'] + df.loc[i,'Power_Parity_Rs_240000_330000'] + df.loc[i,'Power_Parity_Rs_330000_425000'] + df.loc[i,'Power_Parity_Above_Rs_545000']))\n",
    "\n",
    "fill_power_parity_rs_425000_545000(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filling up the Power_Parity_Rs_330000_545000 :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vkBk_xbVOzRk"
   },
   "outputs": [],
   "source": [
    "def fill_power_parity_rs_330000_545000(df):\n",
    "    for i in range(len(df)):\n",
    "        if null_values_filter(df,i,'Power_Parity_Rs_330000_545000') == True:\n",
    "            if null_values_filter(df,i,'Power_Parity_Rs_425000_545000') == null_values_filter(df,i,'Power_Parity_Rs_330000_425000') == False:\n",
    "                df.loc[i,'Power_Parity_Rs_330000_545000'] = int(df.loc[i,'Power_Parity_Rs_330000_425000'] + df.loc[i,'Power_Parity_Rs_425000_545000'])\n",
    "        elif null_values_filter(df,i,'Total_Power_Parity') == null_values_filter(df,i,'Power_Parity_Less_than_Rs_45000') == null_values_filter(df,i,'Power_Parity_Rs_45000_90000') == null_values_filter(df,i,'Power_Parity_Rs_90000_150000') == null_values_filter(df,i,'Power_Parity_Rs_240000_330000') == null_values_filter(df,i,'Power_Parity_Rs_150000_240000') == null_values_filter(df,i,'Power_Parity_Above_Rs_545000') == False:\n",
    "                df.loc[i,'Power_Parity_Rs_330000_545000'] = int(df.loc[i,'Total_Power_Parity'] - (df.loc[i,'Power_Parity_Less_than_Rs_45000'] + df.loc[i,'Power_Parity_Rs_45000_90000'] + df.loc[i,'Power_Parity_Rs_90000_150000'] + df.loc[i,'Power_Parity_Rs_150000_240000'] + df.loc[i,'Power_Parity_Rs_240000_330000'] + df.loc[i,'Power_Parity_Above_Rs_545000']))\n",
    "\n",
    "fill_power_parity_rs_330000_545000(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filling up the Total_Power_Parity column :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CxoGWGv3O4EL"
   },
   "outputs": [],
   "source": [
    "def fill_total_power_parity(df):\n",
    "    for i in range(len(df)):\n",
    "        if null_values_filter(df,i,'Total_Power_Parity') == True:\n",
    "            if null_values_filter(df,i,'Power_Parity_Less_than_Rs_45000') == null_values_filter(df,i,'Power_Parity_Rs_45000_150000') == null_values_filter(df,i,'Power_Parity_Rs_150000_330000') == null_values_filter(df,i,'Power_Parity_Rs_330000_545000') == null_values_filter(df,i,'Power_Parity_Above_Rs_545000') == False:\n",
    "                df.loc[i,'Total_Power_Parity'] = int(df.loc[i,'Power_Parity_Less_than_Rs_45000'] + df.loc[i,'Power_Parity_Rs_45000_150000'] + df.loc[i,'Power_Parity_Rs_150000_330000'] + df.loc[i, 'Power_Parity_Rs_330000_545000'] + df.loc[i,'Power_Parity_Above_Rs_545000'])\n",
    "            elif null_values_filter(df,i,'Power_Parity_Less_than_Rs_45000') == null_values_filter(df,i,'Power_Parity_Rs_45000_90000') == null_values_filter(df,i,'Power_Parity_Rs_90000_150000') == null_values_filter(df,i,'Power_Parity_Rs_150000_240000') == null_values_filter(df,i,'Power_Parity_Rs_240000_330000') == null_values_filter(df,i,'Power_Parity_Rs_330000_425000') == null_values_filter(df,i,'Power_Parity_Rs_425000_545000') == null_values_filter(df,i,'Power_Parity_Above_Rs_545000') == False:\n",
    "                df.loc[i,'Total_Power_Parity'] = int(df.loc[i,'Power_Parity_Less_than_Rs_45000'] + df.loc[i,'Power_Parity_Rs_45000_90000'] + df.loc[i,'Power_Parity_Rs_90000_150000'] + df.loc[i,'Power_Parity_Rs_150000_240000'] + df.loc[i,'Power_Parity_Rs_240000_330000'] + df.loc[i,'Power_Parity_Rs_330000_425000'] + df.loc[i,'Power_Parity_Rs_425000_545000'] + df.loc[i,'Power_Parity_Above_Rs_545000'])\n",
    "\n",
    "fill_total_power_parity(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filling up the Power_Parity_Less_than_Rs_45000 column :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tPGwidxCO300"
   },
   "outputs": [],
   "source": [
    "\n",
    "def fill_power_parity_less_than_rs_45000(df):\n",
    "    for i in range(len(df)):\n",
    "        if null_values_filter(df,i,'Power_Parity_Less_than_Rs_45000') == True:\n",
    "            if null_values_filter(df,i,'Power_Parity_Above_Rs_545000') == null_values_filter(df,i,'Power_Parity_Rs_45000_150000') == null_values_filter(df,i,'Power_Parity_Rs_150000_330000') == null_values_filter(df,i,'Power_Parity_Rs_330000_545000') == null_values_filter(df,i,'Total_Power_Parity') == False:\n",
    "                df.loc[i,'Power_Parity_Less_than_Rs_45000'] = int(df.loc[i,'Total_Power_Parity'] - (df.loc[i,'Power_Parity_Above_Rs_545000'] + df.loc[i,'Power_Parity_Rs_45000_150000'] + df.loc[i,'Power_Parity_Rs_150000_330000'] + df.loc[i, 'Power_Parity_Rs_330000_545000']))\n",
    "            elif null_values_filter(df,i,'Total_Power_Parity') == null_values_filter(df,i,'Power_Parity_Rs_425000_545000') == null_values_filter(df,i,'Power_Parity_Rs_45000_90000') == null_values_filter(df,i,'Power_Parity_Rs_90000_150000') == null_values_filter(df,i,'Power_Parity_Rs_150000_240000') == null_values_filter(df,i,'Power_Parity_Rs_240000_330000') == null_values_filter(df,i,'Power_Parity_Rs_330000_425000') == null_values_filter(df,i,'Power_Parity_Above_Rs_545000') == False:\n",
    "                df.loc[i,'Power_Parity_Less_than_Rs_45000'] = int(df.loc[i,'Total_Power_Parity'] - (df.loc[i,'Power_Parity_Rs_45000_90000'] + df.loc[i,'Power_Parity_Rs_90000_150000'] + df.loc[i,'Power_Parity_Rs_150000_240000'] + df.loc[i,'Power_Parity_Rs_240000_330000'] + df.loc[i,'Power_Parity_Rs_330000_425000'] + df.loc[i,'Power_Parity_Rs_425000_545000'] + df.loc[i,'Power_Parity_Above_Rs_545000']))\n",
    "\n",
    "fill_power_parity_less_than_rs_45000(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filling up the Power_Parity_Above_Rs_545000 column :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ARnmX4w-OzMO"
   },
   "outputs": [],
   "source": [
    "def fill_power_parity_above_rs_545000(df):\n",
    "    for i in range(len(df)):\n",
    "        if null_values_filter(df,i,'Power_Parity_Above_Rs_545000') == True:\n",
    "            if null_values_filter(df,i,'Power_Parity_Less_than_Rs_45000') == null_values_filter(df,i,'Power_Parity_Rs_45000_150000') == null_values_filter(df,i,'Power_Parity_Rs_150000_330000') == null_values_filter(df,i,'Power_Parity_Rs_330000_545000') == null_values_filter(df,i,'Total_Power_Parity') == False:\n",
    "                df.loc[i,'Power_Parity_Above_Rs_545000'] = int(df.loc[i,'Total_Power_Parity'] - (df.loc[i,'Power_Parity_Less_than_Rs_45000'] + df.loc[i,'Power_Parity_Rs_45000_150000'] + df.loc[i,'Power_Parity_Rs_150000_330000'] + df.loc[i, 'Power_Parity_Rs_330000_545000']))\n",
    "            elif null_values_filter(df,i,'Total_Power_Parity') == null_values_filter(df,i,'Power_Parity_Less_than_Rs_45000') == null_values_filter(df,i,'Power_Parity_Rs_45000_90000') == null_values_filter(df,i,'Power_Parity_Rs_90000_150000') == null_values_filter(df,i,'Power_Parity_Rs_150000_240000') == null_values_filter(df,i,'Power_Parity_Rs_240000_330000') == null_values_filter(df,i,'Power_Parity_Rs_330000_425000') == null_values_filter(df,i,'Power_Parity_Rs_425000_545000') == False:\n",
    "                df.loc[i,'Power_Parity_Above_Rs_545000'] = int(df.loc[i,'Total_Power_Parity'] - (df.loc[i,'Power_Parity_Rs_45000_90000'] + df.loc[i,'Power_Parity_Rs_90000_150000'] + df.loc[i,'Power_Parity_Rs_150000_240000'] + df.loc[i,'Power_Parity_Rs_240000_330000'] + df.loc[i,'Power_Parity_Rs_330000_425000'] + df.loc[i,'Power_Parity_Rs_425000_545000'] + df.loc[i,'Power_Parity_Less_than_Rs_45000']))\n",
    "\n",
    "fill_power_parity_above_rs_545000(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Finding the percentage of missing data after cleaning is done ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_aI_bWv3PDx_"
   },
   "outputs": [],
   "source": [
    "missing_data_after_cleaning = missingDataPercent(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a CSV file to store the missing data details to visualize it in the streamlit along with other queries :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5z3ogI5pPDue"
   },
   "outputs": [],
   "source": [
    "missing_data = {\n",
    "    'Columns': df.columns,\n",
    "    'Missing_data_before_cleaning (%)' : missing_data_before_cleaning.values(),\n",
    "    'Missing_data_after_cleaning (%)' : missing_data_after_cleaning.values()\n",
    "    }\n",
    "missing_data_df = pd.DataFrame(missing_data)\n",
    "\n",
    "missing_data_df.to_csv('missing_data.csv', header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing missing data Before & After Cleaning :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 902
    },
    "id": "uyAg8Oq4Oy_u",
    "outputId": "d98d584c-9b55-4ae0-ced4-5f8ef4b3a90f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Columns</th>\n",
       "      <th>Missing_data_before_cleaning (%)</th>\n",
       "      <th>Missing_data_after_cleaning (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>District code</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>State/UT</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>District</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Population</td>\n",
       "      <td>4.69</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Male</td>\n",
       "      <td>4.69</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>Power_Parity_Rs_330000_425000</td>\n",
       "      <td>5.16</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>Power_Parity_Rs_425000_545000</td>\n",
       "      <td>4.69</td>\n",
       "      <td>0.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>Power_Parity_Rs_330000_545000</td>\n",
       "      <td>3.59</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>Power_Parity_Above_Rs_545000</td>\n",
       "      <td>4.69</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>Total_Power_Parity</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>118 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Columns  Missing_data_before_cleaning (%)  \\\n",
       "0                    District code                              0.00   \n",
       "1                         State/UT                              0.00   \n",
       "2                         District                              0.00   \n",
       "3                       Population                              4.69   \n",
       "4                             Male                              4.69   \n",
       "..                             ...                               ...   \n",
       "113  Power_Parity_Rs_330000_425000                              5.16   \n",
       "114  Power_Parity_Rs_425000_545000                              4.69   \n",
       "115  Power_Parity_Rs_330000_545000                              3.59   \n",
       "116   Power_Parity_Above_Rs_545000                              4.69   \n",
       "117             Total_Power_Parity                              5.00   \n",
       "\n",
       "     Missing_data_after_cleaning (%)  \n",
       "0                               0.00  \n",
       "1                               0.00  \n",
       "2                               0.00  \n",
       "3                               0.00  \n",
       "4                               0.00  \n",
       "..                               ...  \n",
       "113                             0.16  \n",
       "114                             0.31  \n",
       "115                             0.16  \n",
       "116                             0.62  \n",
       "117                             0.94  \n",
       "\n",
       "[118 rows x 3 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 639
    },
    "id": "odxyuQAsQIhk",
    "outputId": "e5973d53-7f01-4f44-ff2d-1196e7d79381"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[96], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sheets\n\u001b[0;32m      2\u001b[0m sheet \u001b[38;5;241m=\u001b[39m sheets\u001b[38;5;241m.\u001b[39mInteractiveSheet(df\u001b[38;5;241m=\u001b[39mmissing_data_df)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "from google.colab import sheets\n",
    "sheet = sheets.InteractiveSheet(df=missing_data_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V8QakNhrQn5n"
   },
   "source": [
    "### Task -5 : Save Data to MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JKNP6kx8P8hA",
    "outputId": "5db543cc-372c-4e72-9bf8-e7df64f0341c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pinged your deployment. You successfully connected to MongoDB!\n"
     ]
    }
   ],
   "source": [
    "# Connecting with the MongoDB Locallhost \n",
    "\n",
    "uri = \"mongodb+srv://sashikantaraja1966:12345@cluster0.ndy0rxz.mongodb.net/\"\n",
    "\n",
    "def create_mongo_connection(uri):\n",
    "\n",
    "    # Create a new client and connect to the server\n",
    "    client = MongoClient(uri, server_api=ServerApi('1'))\n",
    "\n",
    "    # Send a ping to confirm a successful connection\n",
    "    try:\n",
    "        client.admin.command('ping')\n",
    "        print(\"Pinged your deployment. You successfully connected to MongoDB!\")\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "create_mongo_connection(uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a DB and Collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "id": "f_vcntjDQedJ"
   },
   "outputs": [],
   "source": [
    "# Creating a DB and Collection\n",
    "\n",
    "def mongo_create_db_collection(uri):\n",
    "    client=MongoClient(f'{uri}').census_db\n",
    "    collection = 'census'\n",
    "\n",
    "    # Checking if the collection already exists\n",
    "    if collection in client.list_collection_names():\n",
    "        client[collection].drop()\n",
    "        client=MongoClient(f'{uri}').census_db.census\n",
    "    else:\n",
    "        client=MongoClient(f\"{uri}\").census_db.census\n",
    "\n",
    "    return client\n",
    "\n",
    "client = mongo_create_db_collection(uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inserting the data into MongoDB *>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X1xZJlMFOfWL"
   },
   "outputs": [],
   "source": [
    "def mongo_insert(client,df):\n",
    "    keys = list(df.columns)\n",
    "    for i in range(len(df)):\n",
    "        values = []\n",
    "        for j in keys:\n",
    "            if j not in ['State/UT','District']:\n",
    "                try:\n",
    "                    values.append(int(df.loc[i,j]))\n",
    "                except:\n",
    "                    values.append(None)\n",
    "            else:\n",
    "                values.append(df.loc[i,j])\n",
    "        doc = dict(zip(keys,values))\n",
    "        client.insert_one(doc)\n",
    "\n",
    "mongo_insert(client,df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "itsxXTDSRI1Y"
   },
   "source": [
    "### Task 6: Database connection and data upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "id": "1FupWvH9OfSw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<mysql.connector.connection_cext.CMySQLConnection object at 0x000002576372F980>\n"
     ]
    }
   ],
   "source": [
    "# Connecting to MySQL server Localhost\n",
    "\n",
    "mydb = mysql.connector.connect(\n",
    " host=\"localhost\",\n",
    " user=\"root\",\n",
    " password=\"\",)\n",
    "\n",
    "print(mydb)\n",
    "mycursor = mydb.cursor(buffered=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating DB and & Manually Giving Names :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Manually giving the names for columns which are more than 65 characters in length as MySQL column names have certain constraints\n",
    "over Column name's length and special character usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Amus9_DNRIXA"
   },
   "outputs": [],
   "source": [
    "\n",
    "def create_db_table(df):\n",
    "    mycursor.execute('CREATE DATABASE IF NOT EXISTS Census_DB')\n",
    "\n",
    "    columns = list()\n",
    "    for i in df.columns:\n",
    "        if i == 'District code':\n",
    "            columns.append('District_Code INT PRIMARY KEY')\n",
    "        elif i == \"State/UT\":\n",
    "            columns.append('State_UT VARCHAR(50)')\n",
    "        elif i == \"District\":\n",
    "            columns.append('District VARCHAR(50)')\n",
    "        elif i == \"Households_with_TV_Computer_Laptop_Telephone_mobile_phone_and_Scooter_Car\":\n",
    "            columns.append(\"Households_TV_Computer_Laptop_Telephone_mobile_phone_Scooter_Car INT\")\n",
    "        elif i == \"Type_of_latrine_facility_Night_soil_disposed_into_open_drain_Households\":\n",
    "            columns.append(\"Type_of_latrine_facility_Night_soil_disposed_into_open_drain INT\")\n",
    "        elif i == \"Type_of_latrine_facility_Flush_pour_flush_latrine_connected_to_other_system_Households\":\n",
    "            columns.append(\"Type_of_latrine_Flush_pour_connected_to_other_system_Households INT\")\n",
    "        elif i == \"Not_having_latrine_facility_within_the_premises_Alternative_source_Open_Households\":\n",
    "            columns.append(\"Not_having_latrine_within_premises_Other_source_Open_Households INT\")\n",
    "        elif i == \"Main_source_of_drinking_water_Handpump_Tubewell_Borewell_Households\":\n",
    "            columns.append(\"Source_of_drinking_water_Handpump_Tubewell_Borewell_Households INT\")\n",
    "        elif i == \"Main_source_of_drinking_water_Other_sources_Spring_River_Canal_Tank_Pond_Lake_Other_sources__Households\":\n",
    "            columns.append(\"Drinking_water_Spring_River_Canal_Tank_Pond_Lake_Other_Household INT\")\n",
    "        else:\n",
    "            columns.append(f'{i} INT')\n",
    "\n",
    "    mycursor.execute(f'CREATE OR REPLACE TABLE Census_DB.census_2011 ({\", \".join(columns)})')\n",
    "    mydb.commit()\n",
    "\n",
    "create_db_table(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the column names from the table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GmxSHAZYRIG5"
   },
   "outputs": [],
   "source": [
    "def get_columns(table_name):\n",
    "    mycursor.execute(f\"DESCRIBE {table_name}\")\n",
    "    table_columns = []\n",
    "    for i in mycursor:\n",
    "        table_columns.append(i[0])\n",
    "\n",
    "    return tuple(table_columns)\n",
    "\n",
    "table_columns = get_columns('Census_DB.census_2011')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ut3T0jasR53O"
   },
   "source": [
    "### Creating Function to insert data into DB\n",
    "\n",
    "- Creating placeholders for the values as we have to insert \"Null\" values inside the table and SQL accepts\n",
    "string formatting in '%s' method.\n",
    "\n",
    "- Using execute many to insert bulk data into table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "id": "rjig6zGHSHQo"
   },
   "outputs": [],
   "source": [
    "def db_insert_data(mongo_client, df, table_columns):\n",
    "    placeholders = \", \".join([\"%s\"] * len(table_columns))\n",
    "    columns = \", \".join(table_columns)\n",
    "\n",
    "    data = []\n",
    "\n",
    "    for i in range(1,len(df)+1):\n",
    "        for j in mongo_client.find({'District code':i}):\n",
    "            data.append(tuple(j.values())[1:])\n",
    "\n",
    "    try :\n",
    "        query = f'INSERT INTO Census_DB.Census_2011 ({columns}) VALUES ({placeholders})'\n",
    "        mycursor.executemany(query, data)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "    mydb.commit()\n",
    "\n",
    "db_insert_data(client, df, table_columns)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
